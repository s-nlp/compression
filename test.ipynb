{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.russian_superglue_models import SpanClassificationModel\n",
    "from transformers import AutoModel, PreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset_configs import (\n",
    "    TASK_NUM_CLASSES,\n",
    "    TASK_TO_CONFIG,\n",
    "    TASK_TO_NAME,\n",
    "    TASK_TYPES,\n",
    ")\n",
    "from utils.russian_superglue_models import (\n",
    "    BertForEntityChoice,\n",
    "    RobertaForEntityChoice,\n",
    "    SpanClassificationModel,\n",
    "    EntityChoiceModel\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass \n",
    "from typing import Dict\n",
    "from transformers import BertConfig, RobertaConfig, AutoModelForSequenceClassification, BertTokenizer, RobertaTokenizer\n",
    "\n",
    "@dataclass\n",
    "class ModelData:\n",
    "    config: object\n",
    "    tokenizer: object\n",
    "    task_types: Dict[str, object]\n",
    "\n",
    "\n",
    "MODEL_CLASSES: Dict[str, ModelData] = {\n",
    "    \"bert\": ModelData(\n",
    "        config=BertConfig,\n",
    "        tokenizer=BertTokenizer,\n",
    "        task_types={\n",
    "            \"classification\": BertForSequenceClassification,\n",
    "            \"entity_choice\": BertForEntityChoice,\n",
    "            \"span_classification\": SpanClassificationModel,\n",
    "        },\n",
    "    ),\n",
    "    \"roberta\": ModelData(\n",
    "        config=RobertaConfig,\n",
    "        tokenizer=RobertaTokenizer,\n",
    "        task_types={\n",
    "            \"classification\": RobertaForSequenceClassification,\n",
    "            \"entity_choice\": RobertaForEntityChoice,\n",
    "            \"span_classification\": SpanClassificationModel,\n",
    "        },\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(args) -> PreTrainedModel:\n",
    "    \"\"\"\n",
    "    Returns a pre-trained model for a given task.\n",
    "\n",
    "    Args:\n",
    "        args: An object that contains the following fields:\n",
    "            - model_name: A string that represents the name of the pre-trained model.\n",
    "            - task_name: A string that represents the name of the task.\n",
    "\n",
    "    Returns:\n",
    "        An instance of a pre-trained model for the given task.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the model or task name is not found in the dictionaries.\n",
    "    \"\"\"\n",
    "    model_data = MODEL_CLASSES.get(args.model_name)\n",
    "    if not model_data:\n",
    "        raise ValueError(f\"Unknown model name: {args.model_name}\")\n",
    "    model_type = model_data.task_types.get(TASK_TYPES[args.task_name])\n",
    "    if not model_type:\n",
    "        raise ValueError(f\"Unknown task name: {args.task_name}\")\n",
    "    num_classes = TASK_NUM_CLASSES.get(args.task_name, 2)\n",
    "    if TASK_TYPES[args.task_name] == 'span_classification':\n",
    "        return SpanClassificationModel(\n",
    "            backbone=AutoModel.from_pretrained(args.model_name_or_path),\n",
    "            num_labels=num_classes,\n",
    "        )\n",
    "    elif TASK_TYPES[args.task_name] == 'entity_choice':\n",
    "        return EntityChoiceModel(\n",
    "            backbone=AutoModel.from_pretrained(args.model_name_or_path)\n",
    "        )\n",
    "    else:\n",
    "        return AutoModelForSequenceClassification.from_pretrained(\n",
    "            args.model_name_or_path, num_labels=num_classes\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, task_name, model_name, model_name_or_path):\n",
    "        self.task_name = task_name\n",
    "        self.model_name = model_name\n",
    "        self.model_name_or_path = model_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "EntityChoiceModel.__init__() got an unexpected keyword argument 'num_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m task \u001b[39min\u001b[39;00m TASK_TO_NAME\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m      2\u001b[0m     args \u001b[39m=\u001b[39m Args(task, \u001b[39m'\u001b[39m\u001b[39mbert\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     get_model(args)\n",
      "Cell \u001b[0;32mIn [15], line 29\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m SpanClassificationModel(\n\u001b[1;32m     25\u001b[0m         backbone\u001b[39m=\u001b[39mAutoModel\u001b[39m.\u001b[39mfrom_pretrained(args\u001b[39m.\u001b[39mmodel_name_or_path),\n\u001b[1;32m     26\u001b[0m         num_labels\u001b[39m=\u001b[39mnum_classes,\n\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     28\u001b[0m \u001b[39melif\u001b[39;00m TASK_TYPES[args\u001b[39m.\u001b[39mtask_name] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mentity_choice\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mreturn\u001b[39;00m EntityChoiceModel(\n\u001b[1;32m     30\u001b[0m         backbone\u001b[39m=\u001b[39;49mAutoModel\u001b[39m.\u001b[39;49mfrom_pretrained(args\u001b[39m.\u001b[39;49mmodel_name_or_path),\n\u001b[1;32m     31\u001b[0m         num_labels\u001b[39m=\u001b[39;49mnum_classes,\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     33\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m AutoModelForSequenceClassification\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     35\u001b[0m         args\u001b[39m.\u001b[39mmodel_name_or_path, num_labels\u001b[39m=\u001b[39mnum_classes\n\u001b[1;32m     36\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: EntityChoiceModel.__init__() got an unexpected keyword argument 'num_labels'"
     ]
    }
   ],
   "source": [
    "for task in TASK_TO_NAME.keys():\n",
    "    args = Args(task, 'bert', 'bert-base-uncased')\n",
    "    get_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args('russe', 'bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpanClassificationModel(\n",
       "  (backbone): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls_fc_layer): FCLayer(\n",
       "    (layers): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (e1_fc_layer): FCLayer(\n",
       "    (layers): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (e2_fc_layer): FCLayer(\n",
       "    (layers): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (label_classifier): FCLayer(\n",
       "    (layers): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): Linear(in_features=2304, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import Dataset, DatasetDict\n",
    "from utils.dataset_configs import TASK_TO_NAME, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-878fdac330808658\n",
      "Found cached dataset json (/home/moskovskiy/.cache/huggingface/datasets/json/default-878fdac330808658/0.0.0)\n",
      "Using custom data configuration default-7a5ed85dcaff75ba\n",
      "Found cached dataset json (/home/moskovskiy/.cache/huggingface/datasets/json/default-7a5ed85dcaff75ba/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_data('rucos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset_configs import TASK_TO_CONFIG\n",
    "config = TASK_TO_CONFIG['rucos'](dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335ffd384e36413a9050912887dd4627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6f4de43344453aae933d1832e2ed8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77149c5a67a24139863bbe975df3d3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf0c4d46f8249af922761dd523f7532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2672108ce3734e27aa601e6b3d937a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76e997863fb43089a285437dfeb26b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8858389c0640ea811701154ddc478c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03df6336ae6e4b2991d540f2874bf814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63b28e5249a4f7e92d57a82779bdc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fb69ec3b5c4343b9746c97e6b759c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarding entity \"-\" ({'start': 261, 'end': 260}) due to it consisting entirely of punctuation\n",
      "Discarding entity \"-\" ({'start': 473, 'end': 472}) due to it consisting entirely of punctuation\n",
      " Discarding entity \"-\" ({'start': 599, 'end': 598}) due to it consisting entirely of punctuation\n",
      "Discarding entity \"-\" ({'start': 756, 'end': 755}) due to it consisting entirely of punctuation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856a5859478b4d2da278a955ce8c4852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e51a35b4547487ab7993f633af69486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff71cc99f48147fc9308f58e8ea3dae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#12:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58c284f55d94305b82875ec204605fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#13:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d8db32271b4db6a6db7f73dc9f6102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#14:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea24031c11e74c62888fb1aef65aa40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#15:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea7aad6314f4bd7a22acb5179a2ed39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#16:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f184893f22c74a1283544bb63ff567e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#17:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5db795cc0df489caf97e68050b00d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#18:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d9628dc64b4d288b167903c7feb06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#19:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa05ab5de5d424b81d4ae2991747079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#20:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a0e3e6ae0448debfd05599a4f1e2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#21:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440b711aae304232bf03c2c329c1f685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#22:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be90d129bc324d31ad8b1f7742381977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#23:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9bd41e0fa24509a8b408b5231c0499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#24:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089a9f5a614d4201aa209b7a19d2640f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#26:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ce977b50444e3fa6c2fa27ad9bdcaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#27:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897ce23e0c6d4400b08e3110144d9ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#28:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4be917b18b47409fa7cdf8cd87ef7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#25:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a01702799f4b4dad2d6c0e2ce3f2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#29:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bebab93715473d84feedeaaf6f5189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#30:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f607f54ffbe431b83b165f2b3526b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#31:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarding entity \" \" ({'start': 244, 'end': 243}) due to it consisting entirely of punctuation\n",
      "Discarding entity \" \" ({'start': 245, 'end': 244}) due to it consisting entirely of punctuation\n",
      "             .    40-      .   -    ,  2005 \n",
      "        ,      .     -    ,      .  ,        ,     .  \n",
      "   \n",
      "                    .\n",
      "@highlight\n",
      "    \n",
      "@highlight\n",
      "-:   \n",
      "@highlight\n",
      " COVID-19     [{'start': 10, 'end': 17, 'text': ''}, {'start': 18, 'end': 28, 'text': ' '}, {'start': 46, 'end': 54, 'text': ''}, {'start': 94, 'end': 107, 'text': ' '}, {'start': 204, 'end': 215, 'text': ' '}, {'start': 255, 'end': 256, 'text': '\\n'}, {'start': 277, 'end': 288, 'text': ' '}, {'start': 362, 'end': 373, 'text': ' '}, {'start': 455, 'end': 460, 'text': ''}, {'start': 505, 'end': 519, 'text': ' '}, {'start': 568, 'end': 576, 'text': ''}, {'start': 576, 'end': 577, 'text': '\\n'}, {'start': 577, 'end': 583, 'text': ''}, {'start': 620, 'end': 621, 'text': '\\n'}, {'start': 672, 'end': 680, 'text': ''}, {'start': 726, 'end': 733, 'text': ''}, {'start': 776, 'end': 777, 'text': '\\n'}, {'start': 787, 'end': 788, 'text': '\\n'}, {'start': 826, 'end': 827, 'text': '\\n'}, {'start': 837, 'end': 838, 'text': '\\n'}, {'start': 838, 'end': 846, 'text': ''}, {'start': 847, 'end': 854, 'text': ''}, {'start': 884, 'end': 885, 'text': '\\n'}, {'start': 895, 'end': 896, 'text': '\\n'}, {'start': 936, 'end': 944, 'text': ''}]\n",
      "             .    40-      .   -    ,  2005 \n",
      "        ,      .     -    ,      .  ,        ,     .  \n",
      "   \n",
      "                    .\n",
      "@highlight\n",
      "    \n",
      "@highlight\n",
      "-:   \n",
      "@highlight\n",
      " COVID-19     [{'start': 10, 'end': 17, 'text': ''}, {'start': 18, 'end': 28, 'text': ' '}, {'start': 46, 'end': 54, 'text': ''}, {'start': 94, 'end': 107, 'text': ' '}, {'start': 204, 'end': 215, 'text': ' '}, {'start': 255, 'end': 256, 'text': '\\n'}, {'start': 277, 'end': 288, 'text': ' '}, {'start': 362, 'end': 373, 'text': ' '}, {'start': 455, 'end': 460, 'text': ''}, {'start': 505, 'end': 519, 'text': ' '}, {'start': 568, 'end': 576, 'text': ''}, {'start': 576, 'end': 577, 'text': '\\n'}, {'start': 577, 'end': 583, 'text': ''}, {'start': 620, 'end': 621, 'text': '\\n'}, {'start': 672, 'end': 680, 'text': ''}, {'start': 726, 'end': 733, 'text': ''}, {'start': 776, 'end': 777, 'text': '\\n'}, {'start': 787, 'end': 788, 'text': '\\n'}, {'start': 826, 'end': 827, 'text': '\\n'}, {'start': 837, 'end': 838, 'text': '\\n'}, {'start': 838, 'end': 846, 'text': ''}, {'start': 847, 'end': 854, 'text': ''}, {'start': 884, 'end': 885, 'text': '\\n'}, {'start': 895, 'end': 896, 'text': '\\n'}, {'start': 936, 'end': 944, 'text': ''}]\n",
      "             .    40-      .   -    ,  2005 \n",
      "        ,      .     -    ,      .  ,        ,     .  \n",
      "   \n",
      "                    .\n",
      "@highlight\n",
      "    \n",
      "@highlight\n",
      "-:   \n",
      "@highlight\n",
      " COVID-19     [{'start': 10, 'end': 17, 'text': ''}, {'start': 18, 'end': 28, 'text': ' '}, {'start': 46, 'end': 54, 'text': ''}, {'start': 94, 'end': 107, 'text': ' '}, {'start': 204, 'end': 215, 'text': ' '}, {'start': 255, 'end': 256, 'text': '\\n'}, {'start': 277, 'end': 288, 'text': ' '}, {'start': 362, 'end': 373, 'text': ' '}, {'start': 455, 'end': 460, 'text': ''}, {'start': 505, 'end': 519, 'text': ' '}, {'start': 568, 'end': 576, 'text': ''}, {'start': 576, 'end': 577, 'text': '\\n'}, {'start': 577, 'end': 583, 'text': ''}, {'start': 620, 'end': 621, 'text': '\\n'}, {'start': 672, 'end': 680, 'text': ''}, {'start': 726, 'end': 733, 'text': ''}, {'start': 776, 'end': 777, 'text': '\\n'}, {'start': 787, 'end': 788, 'text': '\\n'}, {'start': 826, 'end': 827, 'text': '\\n'}, {'start': 837, 'end': 838, 'text': '\\n'}, {'start': 838, 'end': 846, 'text': ''}, {'start': 847, 'end': 854, 'text': ''}, {'start': 884, 'end': 885, 'text': '\\n'}, {'start': 895, 'end': 896, 'text': '\\n'}, {'start': 936, 'end': 944, 'text': ''}]\n",
      "             .    40-      .   -    ,  2005 \n",
      "        ,      .     -    ,      .  ,        ,     .  \n",
      "   \n",
      "                    .\n",
      "@highlight\n",
      "    \n",
      "@highlight\n",
      "-:   \n",
      "@highlight\n",
      " COVID-19     [{'start': 10, 'end': 17, 'text': ''}, {'start': 18, 'end': 28, 'text': ' '}, {'start': 46, 'end': 54, 'text': ''}, {'start': 94, 'end': 107, 'text': ' '}, {'start': 204, 'end': 215, 'text': ' '}, {'start': 255, 'end': 256, 'text': '\\n'}, {'start': 277, 'end': 288, 'text': ' '}, {'start': 362, 'end': 373, 'text': ' '}, {'start': 455, 'end': 460, 'text': ''}, {'start': 505, 'end': 519, 'text': ' '}, {'start': 568, 'end': 576, 'text': ''}, {'start': 576, 'end': 577, 'text': '\\n'}, {'start': 577, 'end': 583, 'text': ''}, {'start': 620, 'end': 621, 'text': '\\n'}, {'start': 672, 'end': 680, 'text': ''}, {'start': 726, 'end': 733, 'text': ''}, {'start': 776, 'end': 777, 'text': '\\n'}, {'start': 787, 'end': 788, 'text': '\\n'}, {'start': 826, 'end': 827, 'text': '\\n'}, {'start': 837, 'end': 838, 'text': '\\n'}, {'start': 838, 'end': 846, 'text': ''}, {'start': 847, 'end': 854, 'text': ''}, {'start': 884, 'end': 885, 'text': '\\n'}, {'start': 895, 'end': 896, 'text': '\\n'}, {'start': 936, 'end': 944, 'text': ''}]\n",
      "             .    40-      .   -    ,  2005 \n",
      "        ,      .     -    ,      .  ,        ,     .  \n",
      "   \n",
      "                    .\n",
      "@highlight\n",
      "    \n",
      "@highlight\n",
      "-:   \n",
      "@highlight\n",
      " COVID-19     [{'start': 10, 'end': 17, 'text': ''}, {'start': 18, 'end': 28, 'text': ' '}, {'start': 46, 'end': 54, 'text': ''}, {'start': 94, 'end': 107, 'text': ' '}, {'start': 204, 'end': 215, 'text': ' '}, {'start': 255, 'end': 256, 'text': '\\n'}, {'start': 277, 'end': 288, 'text': ' '}, {'start': 362, 'end': 373, 'text': ' '}, {'start': 455, 'end': 460, 'text': ''}, {'start': 505, 'end': 519, 'text': ' '}, {'start': 568, 'end': 576, 'text': ''}, {'start': 576, 'end': 577, 'text': '\\n'}, {'start': 577, 'end': 583, 'text': ''}, {'start': 620, 'end': 621, 'text': '\\n'}, {'start': 672, 'end': 680, 'text': ''}, {'start': 726, 'end': 733, 'text': ''}, {'start': 776, 'end': 777, 'text': '\\n'}, {'start': 787, 'end': 788, 'text': '\\n'}, {'start': 826, 'end': 827, 'text': '\\n'}, {'start': 837, 'end': 838, 'text': '\\n'}, {'start': 838, 'end': 846, 'text': ''}, {'start': 847, 'end': 854, 'text': ''}, {'start': 884, 'end': 885, 'text': '\\n'}, {'start': 895, 'end': 896, 'text': '\\n'}, {'start': 936, 'end': 944, 'text': ''}]\n",
      "             .    40-      .   -    ,  2005 \n",
      "        ,      .     -    ,      .  ,        ,     .  \n",
      "   \n",
      "                    .\n",
      "@highlight\n",
      "    \n",
      "@highlight\n",
      "-:   \n",
      "@highlight\n",
      " COVID-19     [{'start': 10, 'end': 17, 'text': ''}, {'start': 18, 'end': 28, 'text': ' '}, {'start': 46, 'end': 54, 'text': ''}, {'start': 94, 'end': 107, 'text': ' '}, {'start': 204, 'end': 215, 'text': ' '}, {'start': 255, 'end': 256, 'text': '\\n'}, {'start': 277, 'end': 288, 'text': ' '}, {'start': 362, 'end': 373, 'text': ' '}, {'start': 455, 'end': 460, 'text': ''}, {'start': 505, 'end': 519, 'text': ' '}, {'start': 568, 'end': 576, 'text': ''}, {'start': 576, 'end': 577, 'text': '\\n'}, {'start': 577, 'end': 583, 'text': ''}, {'start': 620, 'end': 621, 'text': '\\n'}, {'start': 672, 'end': 680, 'text': ''}, {'start': 726, 'end': 733, 'text': ''}, {'start': 776, 'end': 777, 'text': '\\n'}, {'start': 787, 'end': 788, 'text': '\\n'}, {'start': 826, 'end': 827, 'text': '\\n'}, {'start': 837, 'end': 838, 'text': '\\n'}, {'start': 838, 'end': 846, 'text': ''}, {'start': 847, 'end': 854, 'text': ''}, {'start': 884, 'end': 885, 'text': '\\n'}, {'start': 895, 'end': 896, 'text': '\\n'}, {'start': 936, 'end': 944, 'text': ''}]\n",
      "             .    40-      .   -    ,  2005 \n",
      "        ,      .     -    ,      .  ,        ,     .  \n",
      "   \n",
      "                    .\n",
      "@highlight\n",
      "    \n",
      "@highlight\n",
      "-:   \n",
      "@highlight\n",
      " COVID-19     [{'start': 10, 'end': 17, 'text': ''}, {'start': 18, 'end': 28, 'text': ' '}, {'start': 46, 'end': 54, 'text': ''}, {'start': 94, 'end': 107, 'text': ' '}, {'start': 204, 'end': 215, 'text': ' '}, {'start': 255, 'end': 256, 'text': '\\n'}, {'start': 277, 'end': 288, 'text': ' '}, {'start': 362, 'end': 373, 'text': ' '}, {'start': 455, 'end': 460, 'text': ''}, {'start': 505, 'end': 519, 'text': ' '}, {'start': 568, 'end': 576, 'text': ''}, {'start': 576, 'end': 577, 'text': '\\n'}, {'start': 577, 'end': 583, 'text': ''}, {'start': 620, 'end': 621, 'text': '\\n'}, {'start': 672, 'end': 680, 'text': ''}, {'start': 726, 'end': 733, 'text': ''}, {'start': 776, 'end': 777, 'text': '\\n'}, {'start': 787, 'end': 788, 'text': '\\n'}, {'start': 826, 'end': 827, 'text': '\\n'}, {'start': 837, 'end': 838, 'text': '\\n'}, {'start': 838, 'end': 846, 'text': ''}, {'start': 847, 'end': 854, 'text': ''}, {'start': 884, 'end': 885, 'text': '\\n'}, {'start': 895, 'end': 896, 'text': '\\n'}, {'start': 936, 'end': 944, 'text': ''}]\n",
      "             .    40-      .   -    ,  2005 \n",
      "        ,      .     -    ,      .  ,        ,     .  \n",
      "   \n",
      "                    .\n",
      "@highlight\n",
      "    \n",
      "@highlight\n",
      "-:   \n",
      "@highlight\n",
      " COVID-19     [{'start': 10, 'end': 17, 'text': ''}, {'start': 18, 'end': 28, 'text': ' '}, {'start': 46, 'end': 54, 'text': ''}, {'start': 94, 'end': 107, 'text': ' '}, {'start': 204, 'end': 215, 'text': ' '}, {'start': 255, 'end': 256, 'text': '\\n'}, {'start': 277, 'end': 288, 'text': ' '}, {'start': 362, 'end': 373, 'text': ' '}, {'start': 455, 'end': 460, 'text': ''}, {'start': 505, 'end': 519, 'text': ' '}, {'start': 568, 'end': 576, 'text': ''}, {'start': 576, 'end': 577, 'text': '\\n'}, {'start': 577, 'end': 583, 'text': ''}, {'start': 620, 'end': 621, 'text': '\\n'}, {'start': 672, 'end': 680, 'text': ''}, {'start': 726, 'end': 733, 'text': ''}, {'start': 776, 'end': 777, 'text': '\\n'}, {'start': 787, 'end': 788, 'text': '\\n'}, {'start': 826, 'end': 827, 'text': '\\n'}, {'start': 837, 'end': 838, 'text': '\\n'}, {'start': 838, 'end': 846, 'text': ''}, {'start': 847, 'end': 854, 'text': ''}, {'start': 884, 'end': 885, 'text': '\\n'}, {'start': 895, 'end': 896, 'text': '\\n'}, {'start': 936, 'end': 944, 'text': ''}]\n",
      "             .    40-      .   -    ,  2005 \n",
      "        ,      .     -    ,      .  ,        ,     .  \n",
      "   \n",
      "                    .\n",
      "@highlight\n",
      "    \n",
      "@highlight\n",
      "-:   \n",
      "@highlight\n",
      " COVID-19     [{'start': 10, 'end': 17, 'text': ''}, {'start': 18, 'end': 28, 'text': ' '}, {'start': 46, 'end': 54, 'text': ''}, {'start': 94, 'end': 107, 'text': ' '}, {'start': 204, 'end': 215, 'text': ' '}, {'start': 255, 'end': 256, 'text': '\\n'}, {'start': 277, 'end': 288, 'text': ' '}, {'start': 362, 'end': 373, 'text': ' '}, {'start': 455, 'end': 460, 'text': ''}, {'start': 505, 'end': 519, 'text': ' '}, {'start': 568, 'end': 576, 'text': ''}, {'start': 576, 'end': 577, 'text': '\\n'}, {'start': 577, 'end': 583, 'text': ''}, {'start': 620, 'end': 621, 'text': '\\n'}, {'start': 672, 'end': 680, 'text': ''}, {'start': 726, 'end': 733, 'text': ''}, {'start': 776, 'end': 777, 'text': '\\n'}, {'start': 787, 'end': 788, 'text': '\\n'}, {'start': 826, 'end': 827, 'text': '\\n'}, {'start': 837, 'end': 838, 'text': '\\n'}, {'start': 838, 'end': 846, 'text': ''}, {'start': 847, 'end': 854, 'text': ''}, {'start': 884, 'end': 885, 'text': '\\n'}, {'start': 895, 'end': 896, 'text': '\\n'}, {'start': 936, 'end': 944, 'text': ''}]\n",
      "  ,       , .           PERN  .      , 11.         2020 ,   .       Orlen   ,     ,         .      .\n",
      "@highlight\n",
      "       \n",
      "@highlight\n",
      "      \n",
      "@highlight\n",
      "     [{'start': 72, 'end': 78, 'text': ''}, {'start': 121, 'end': 122, 'text': '\\xa0'}, {'start': 165, 'end': 169, 'text': 'PERN'}, {'start': 170, 'end': 187, 'text': ' '}, {'start': 208, 'end': 212, 'text': ''}, {'start': 224, 'end': 225, 'text': '\\xa0'}, {'start': 371, 'end': 376, 'text': 'Orlen'}, {'start': 574, 'end': 580, 'text': ''}, {'start': 596, 'end': 602, 'text': ''}, {'start': 645, 'end': 651, 'text': ''}, {'start': 662, 'end': 669, 'text': ''}, {'start': 710, 'end': 720, 'text': ''}, {'start': 745, 'end': 751, 'text': ''}]\n",
      "  ,       , .           PERN  .      , 11.         2020 ,   .       Orlen   ,     ,         .      .\n",
      "@highlight\n",
      "       \n",
      "@highlight\n",
      "      \n",
      "@highlight\n",
      "     [{'start': 72, 'end': 78, 'text': ''}, {'start': 121, 'end': 122, 'text': '\\xa0'}, {'start': 165, 'end': 169, 'text': 'PERN'}, {'start': 170, 'end': 187, 'text': ' '}, {'start': 208, 'end': 212, 'text': ''}, {'start': 224, 'end': 225, 'text': '\\xa0'}, {'start': 371, 'end': 376, 'text': 'Orlen'}, {'start': 574, 'end': 580, 'text': ''}, {'start': 596, 'end': 602, 'text': ''}, {'start': 645, 'end': 651, 'text': ''}, {'start': 662, 'end': 669, 'text': ''}, {'start': 710, 'end': 720, 'text': ''}, {'start': 745, 'end': 751, 'text': ''}]\n",
      "         ,    140-         ,     ,   .        . ,        ,       ,        !,          .          -  .      ,   !   .   . -     , 140-        ,       .\n",
      "@highlight\n",
      "    \n",
      "@highlight\n",
      "        \n",
      "@highlight\n",
      "       [{'start': 0, 'end': 23, 'text': ' '}, {'start': 26, 'end': 38, 'text': ''}, {'start': 176, 'end': 183, 'text': ' '}, {'start': 184, 'end': 198, 'text': ' '}, {'start': 215, 'end': 216, 'text': '\\xa0'}, {'start': 218, 'end': 237, 'text': ' '}, {'start': 429, 'end': 430, 'text': '\\xa0'}, {'start': 433, 'end': 439, 'text': ''}, {'start': 465, 'end': 466, 'text': '\\xa0'}, {'start': 486, 'end': 492, 'text': ''}, {'start': 537, 'end': 538, 'text': '\\xa0'}, {'start': 541, 'end': 547, 'text': ''}, {'start': 561, 'end': 562, 'text': '\\xa0'}, {'start': 754, 'end': 760, 'text': ''}, {'start': 861, 'end': 865, 'text': ''}, {'start': 866, 'end': 878, 'text': ' '}, {'start': 906, 'end': 912, 'text': ''}, {'start': 948, 'end': 960, 'text': ''}, {'start': 1005, 'end': 1011, 'text': ''}, {'start': 1029, 'end': 1035, 'text': ''}, {'start': 1065, 'end': 1071, 'text': ''}, {'start': 1096, 'end': 1102, 'text': ''}, {'start': 1129, 'end': 1141, 'text': ''}, {'start': 1167, 'end': 1173, 'text': ''}]\n",
      "         ,    140-         ,     ,   .        . ,        ,       ,        !,          .          -  .      ,   !   .   . -     , 140-        ,       .\n",
      "@highlight\n",
      "    \n",
      "@highlight\n",
      "        \n",
      "@highlight\n",
      "       [{'start': 0, 'end': 23, 'text': ' '}, {'start': 26, 'end': 38, 'text': ''}, {'start': 176, 'end': 183, 'text': ' '}, {'start': 184, 'end': 198, 'text': ' '}, {'start': 215, 'end': 216, 'text': '\\xa0'}, {'start': 218, 'end': 237, 'text': ' '}, {'start': 429, 'end': 430, 'text': '\\xa0'}, {'start': 433, 'end': 439, 'text': ''}, {'start': 465, 'end': 466, 'text': '\\xa0'}, {'start': 486, 'end': 492, 'text': ''}, {'start': 537, 'end': 538, 'text': '\\xa0'}, {'start': 541, 'end': 547, 'text': ''}, {'start': 561, 'end': 562, 'text': '\\xa0'}, {'start': 754, 'end': 760, 'text': ''}, {'start': 861, 'end': 865, 'text': ''}, {'start': 866, 'end': 878, 'text': ' '}, {'start': 906, 'end': 912, 'text': ''}, {'start': 948, 'end': 960, 'text': ''}, {'start': 1005, 'end': 1011, 'text': ''}, {'start': 1029, 'end': 1035, 'text': ''}, {'start': 1065, 'end': 1071, 'text': ''}, {'start': 1096, 'end': 1102, 'text': ''}, {'start': 1129, 'end': 1141, 'text': ''}, {'start': 1167, 'end': 1173, 'text': ''}]\n",
      "         ,    140-         ,     ,   .        . ,        ,       ,        !,          .          -  .      ,   !   .   . -     , 140-        ,       .\n",
      "@highlight\n",
      "    \n",
      "@highlight\n",
      "        \n",
      "@highlight\n",
      "       [{'start': 0, 'end': 23, 'text': ' '}, {'start': 26, 'end': 38, 'text': ''}, {'start': 176, 'end': 183, 'text': ' '}, {'start': 184, 'end': 198, 'text': ' '}, {'start': 215, 'end': 216, 'text': '\\xa0'}, {'start': 218, 'end': 237, 'text': ' '}, {'start': 429, 'end': 430, 'text': '\\xa0'}, {'start': 433, 'end': 439, 'text': ''}, {'start': 465, 'end': 466, 'text': '\\xa0'}, {'start': 486, 'end': 492, 'text': ''}, {'start': 537, 'end': 538, 'text': '\\xa0'}, {'start': 541, 'end': 547, 'text': ''}, {'start': 561, 'end': 562, 'text': '\\xa0'}, {'start': 754, 'end': 760, 'text': ''}, {'start': 861, 'end': 865, 'text': ''}, {'start': 866, 'end': 878, 'text': ' '}, {'start': 906, 'end': 912, 'text': ''}, {'start': 948, 'end': 960, 'text': ''}, {'start': 1005, 'end': 1011, 'text': ''}, {'start': 1029, 'end': 1035, 'text': ''}, {'start': 1065, 'end': 1071, 'text': ''}, {'start': 1096, 'end': 1102, 'text': ''}, {'start': 1129, 'end': 1141, 'text': ''}, {'start': 1167, 'end': 1173, 'text': ''}]\n",
      "         ,    140-         ,     ,   .        . ,        ,       ,        !,          .          -  .      ,   !   .   . -     , 140-        ,       .\n",
      "@highlight\n",
      "    \n",
      "@highlight\n",
      "        \n",
      "@highlight\n",
      "       [{'start': 0, 'end': 23, 'text': ' '}, {'start': 26, 'end': 38, 'text': ''}, {'start': 176, 'end': 183, 'text': ' '}, {'start': 184, 'end': 198, 'text': ' '}, {'start': 215, 'end': 216, 'text': '\\xa0'}, {'start': 218, 'end': 237, 'text': ' '}, {'start': 429, 'end': 430, 'text': '\\xa0'}, {'start': 433, 'end': 439, 'text': ''}, {'start': 465, 'end': 466, 'text': '\\xa0'}, {'start': 486, 'end': 492, 'text': ''}, {'start': 537, 'end': 538, 'text': '\\xa0'}, {'start': 541, 'end': 547, 'text': ''}, {'start': 561, 'end': 562, 'text': '\\xa0'}, {'start': 754, 'end': 760, 'text': ''}, {'start': 861, 'end': 865, 'text': ''}, {'start': 866, 'end': 878, 'text': ' '}, {'start': 906, 'end': 912, 'text': ''}, {'start': 948, 'end': 960, 'text': ''}, {'start': 1005, 'end': 1011, 'text': ''}, {'start': 1029, 'end': 1035, 'text': ''}, {'start': 1065, 'end': 1071, 'text': ''}, {'start': 1096, 'end': 1102, 'text': ''}, {'start': 1129, 'end': 1141, 'text': ''}, {'start': 1167, 'end': 1173, 'text': ''}]\n",
      "         ,    140-         ,     ,   .        . ,        ,       ,        !,          .          -  .      ,   !   .   . -     , 140-        ,       .\n",
      "@highlight\n",
      "    \n",
      "@highlight\n",
      "        \n",
      "@highlight\n",
      "       [{'start': 0, 'end': 23, 'text': ' '}, {'start': 26, 'end': 38, 'text': ''}, {'start': 176, 'end': 183, 'text': ' '}, {'start': 184, 'end': 198, 'text': ' '}, {'start': 215, 'end': 216, 'text': '\\xa0'}, {'start': 218, 'end': 237, 'text': ' '}, {'start': 429, 'end': 430, 'text': '\\xa0'}, {'start': 433, 'end': 439, 'text': ''}, {'start': 465, 'end': 466, 'text': '\\xa0'}, {'start': 486, 'end': 492, 'text': ''}, {'start': 537, 'end': 538, 'text': '\\xa0'}, {'start': 541, 'end': 547, 'text': ''}, {'start': 561, 'end': 562, 'text': '\\xa0'}, {'start': 754, 'end': 760, 'text': ''}, {'start': 861, 'end': 865, 'text': ''}, {'start': 866, 'end': 878, 'text': ' '}, {'start': 906, 'end': 912, 'text': ''}, {'start': 948, 'end': 960, 'text': ''}, {'start': 1005, 'end': 1011, 'text': ''}, {'start': 1029, 'end': 1035, 'text': ''}, {'start': 1065, 'end': 1071, 'text': ''}, {'start': 1096, 'end': 1102, 'text': ''}, {'start': 1129, 'end': 1141, 'text': ''}, {'start': 1167, 'end': 1173, 'text': ''}]\n",
      "            .     101 Great Goals.    52-    .          .     2 ,        .   2017             .\n",
      "@highlight\n",
      "   2017    \n",
      "@highlight\n",
      "      \n",
      "@highlight\n",
      "      [{'start': 21, 'end': 26, 'text': ''}, {'start': 72, 'end': 82, 'text': ''}, {'start': 83, 'end': 100, 'text': ' '}, {'start': 127, 'end': 142, 'text': '101 Great Goals'}, {'start': 174, 'end': 202, 'text': '   '}, {'start': 238, 'end': 245, 'text': ''}, {'start': 259, 'end': 260, 'text': '\\xa0'}, {'start': 280, 'end': 287, 'text': ''}, {'start': 462, 'end': 469, 'text': ''}, {'start': 498, 'end': 505, 'text': ''}, {'start': 564, 'end': 568, 'text': ''}, {'start': 591, 'end': 601, 'text': ''}, {'start': 614, 'end': 631, 'text': ' '}, {'start': 683, 'end': 690, 'text': ''}]\n",
      "                                  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06b759223234d4fa5f7e552cebee82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ce27e9274d4116b1311aefff97201d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a47f8c402e401c9b591dbfa750d685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8adea26e7e44efbab8563bad2817ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83911f60c13748f1b8bfd48337e1f331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2c7c1ab2a2413688210d4ee644bdca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86618456c2e417cb4edeffadfa35d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d7d3f958f24705a9ef3cbe27b0fee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b5779e2ae54d71b0f5c1c7c53b385d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d527f177b2da415c9c54cb087dda5830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9f4f7249744077a2212b68564f37c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652ba4cd236048239c0296a182f3d65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a9fb1a39cf43edac2ca79a2f20657b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#12:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-              .    .net.       ,  .                 ( ).      ,      .   ,       .\n",
      "@highlight\n",
      "         \n",
      "@highlight\n",
      "     \n",
      "@highlight\n",
      "         [{'start': 59, 'end': 60, 'text': '\\xa0'}, {'start': 62, 'end': 69, 'text': ''}, {'start': 79, 'end': 84, 'text': ''}, {'start': 208, 'end': 212, 'text': ''}, {'start': 222, 'end': 227, 'text': ''}, {'start': 231, 'end': 249, 'text': ' '}, {'start': 361, 'end': 374, 'text': ''}, {'start': 377, 'end': 387, 'text': ''}, {'start': 388, 'end': 395, 'text': ''}, {'start': 545, 'end': 551, 'text': ''}, {'start': 586, 'end': 595, 'text': ''}, {'start': 599, 'end': 615, 'text': ' '}, {'start': 659, 'end': 664, 'text': ''}, {'start': 701, 'end': 710, 'text': ''}]\n",
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e19cf868964ef296d0d80c9f636697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#13:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408bcfe16ab8449a870d9645907ec791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#14:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958af326c1df4ff79d8753ec0e65b7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#15:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a598a030ed31486c822cc2b8979f638f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#16:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c501be02682845e3a42176a6c58e5d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#17:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b556e16649804ef5ac46dd69575711e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#18:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b14c253831b4fbf89eeff30bdeebba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#19:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f232b8d70c242518981d0f55cd4c576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#20:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6da516dfdd4a5697c9c2188337cc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#21:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622427b6dc3f41ef86dfb5d1cd7f9b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#22:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f967db854c540a18a0a679107799d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#23:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c166b1980a5a4537953f35f8dadc9ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#24:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8bd6906b8a4120a9383ca48e144d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#27:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ded28253904412a158c2cc0ea5d9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#25:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1f6c773a21482a869891e79566a141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#28:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec21b571e13a4bebbc54e99c299c6533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#26:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6d396a86754847b4c7d7f46219b21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#29:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57763cbf2a6647589804b1d3b38383ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#30:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24f66fe44ab46119de6d4fd31d20597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#31:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ,     .    , 28 ,  .  ,          ,   ,  20  .      ,     , ,      ,      ,   .   ,     ,     ,   .    ,   -  ,    ,      .\n",
      "@highlight\n",
      "     \n",
      "@highlight\n",
      "     \n",
      "@highlight\n",
      "       [{'start': 0, 'end': 6, 'text': ''}, {'start': 9, 'end': 20, 'text': ''}, {'start': 77, 'end': 91, 'text': ' '}, {'start': 84, 'end': 91, 'text': ''}, {'start': 138, 'end': 147, 'text': ''}, {'start': 315, 'end': 327, 'text': ' '}, {'start': 549, 'end': 550, 'text': '\\xa0'}, {'start': 584, 'end': 593, 'text': ''}, {'start': 664, 'end': 675, 'text': ''}, {'start': 738, 'end': 758, 'text': ' '}, {'start': 749, 'end': 758, 'text': ''}, {'start': 771, 'end': 778, 'text': ''}, {'start': 826, 'end': 833, 'text': ''}, {'start': 841, 'end': 847, 'text': ''}, {'start': 870, 'end': 876, 'text': ''}, {'start': 888, 'end': 895, 'text': ''}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "from functools import partial\n",
    "tokenizer = BertTokenizerFast.from_pretrained('cointegrated/rubert-tiny2')\n",
    "processed_dataset = dataset.map(\n",
    "    partial(\n",
    "        config.process_data, tokenizer=tokenizer, max_length=512\n",
    "    ),\n",
    "    num_proc=32,\n",
    "    keep_in_memory=True,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['idx', 'passage', 'qas', 'input_ids', 'token_type_ids', 'attention_mask', 'entity_mask', 'entities', 'length', 'answers', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "print(processed_dataset[\"train\"][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': ' ,        .   @placeholder            .',\n",
       "  'answers': [{'start': 789, 'end': 798, 'text': ''}],\n",
       "  'idx': 0}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset[\"train\"][0]['qas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"passage\", \"qas\", \"entities\", \"answers\", \"length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 0,\n",
       " 'target': {'span1_text': '  ',\n",
       "  'span2_text': ' ',\n",
       "  'span1_index': 0,\n",
       "  'span2_index': 10},\n",
       " 'label': True,\n",
       " 'text': '       ,     .'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset_configs import DatasetConfig\n",
    "from transformers import PreTrainedTokenizer, EvalPrediction\n",
    "from typing import List \n",
    "\n",
    "def find_sub_list(sublist: List[int], main_list: List[int]):\n",
    "    sublist_length=len(sublist)\n",
    "    for idx in (index for index, element in enumerate(main_list) if element == sublist[0]):\n",
    "        if main_list[idx: idx + sublist_length] == sublist:\n",
    "            start = idx\n",
    "            end = idx + sublist_length \n",
    "    print(start, end)\n",
    "    return start, end  \n",
    "\n",
    "class RWSDConfig(DatasetConfig):\n",
    "\n",
    "    best_metric: str = \"accuracy\"\n",
    "    num_classes: int = 2\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_data(examples, tokenizer: PreTrainedTokenizer, max_length: int):\n",
    "        # print(examples)\n",
    "        result = tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=\"longest_first\",\n",
    "            return_token_type_ids=True,\n",
    "            max_length=245,\n",
    "        )\n",
    "        # print(result)\n",
    "\n",
    "        e1_masks, e2_masks = [], [] \n",
    "        \n",
    "        for i, sample in enumerate(examples[\"target\"]):\n",
    "            e1_mask = np.zeros_like(result[\"input_ids\"], dtype=int)\n",
    "            e2_mask = np.zeros_like(result[\"input_ids\"], dtype=int)\n",
    "\n",
    "            e1_span = tokenizer(\n",
    "                sample[\"span1_text\"],\n",
    "                add_special_tokens=False,\n",
    "                return_attention_mask=False,\n",
    "                return_token_type_ids=False,\n",
    "            )[\"input_ids\"]\n",
    "            e2_span = tokenizer(\n",
    "                sample[\"span2_text\"],\n",
    "                add_special_tokens=False,\n",
    "                return_attention_mask=False,\n",
    "                return_token_type_ids=False,\n",
    "            )[\"input_ids\"]\n",
    "            for mask, span in zip((e1_mask, e2_mask), (e1_span, e2_span)):\n",
    "                start, end = find_sub_list(span, result[\"input_ids\"][i])\n",
    "                mask[start: end] = 1\n",
    "\n",
    "            e1_masks.append(e1_mask)\n",
    "            e2_masks.append(e2_mask)\n",
    "\n",
    "        result[\"e1_mask\"] = e1_masks\n",
    "        result[\"e2_mask\"] = e2_masks\n",
    "\n",
    "        if isinstance(examples[\"label\"], list):\n",
    "            result[\"labels\"] = [int(x) for x in examples[\"label\"]]\n",
    "        else:\n",
    "            result[\"labels\"] = int(examples[\"label\"])\n",
    "        \n",
    "        return result  \n",
    "\n",
    "    def compute_metrics(self, predictions: EvalPrediction, split: str, **kwargs):\n",
    "        preds = np.argmax(predictions.predictions, axis=1)\n",
    "        return {\n",
    "            \"accuracy\": accuracy_score(\n",
    "                y_true=predictions.label_ids.astype(np.float32), y_pred=preds\n",
    "            )\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RWSDConfig(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizerFast\n",
    "# from functools import partial\n",
    "# tokenizer = BertTokenizerFast.from_pretrained('cointegrated/rubert-tiny2')\n",
    "# processed_dataset = dataset.map(\n",
    "#     partial(\n",
    "#         config.process_data, tokenizer=tokenizer, max_length=255\n",
    "#     ),\n",
    "#     num_proc=32,\n",
    "#     keep_in_memory=True,\n",
    "#     batched=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n",
      "12 15)\n",
      "5 7, 15)\n",
      "12 15)\n",
      "1 4, 15)\n",
      "12 15)\n",
      "5 7, 15)\n",
      "12 15)\n",
      "1 2, 15)\n",
      "10 13)\n",
      "6 7, 13)\n",
      "10 13)\n",
      "1 2, 13)\n",
      "10 13)\n",
      "6 7, 13)\n",
      "10 13)\n",
      "1 2, 13)\n",
      "9 112)\n",
      "3 5 11)\n",
      "9 115)\n",
      "1 2 11)\n",
      "9 112)\n",
      "3 5 11)\n",
      "9 115)\n",
      "1 2 11)\n",
      "9 132)\n",
      "3 5 13)\n",
      "9 135)\n",
      "1 2 13)\n",
      "9 122)\n",
      "3 5 12)\n",
      "9 125)\n",
      "1 2 12)\n",
      "8 102)\n",
      "3 5 10)\n",
      "8 105)\n",
      "1 2 10)\n",
      "9 112)\n",
      "3 5 11)\n",
      "9 115)\n",
      "1 4 11)\n",
      "10 12)\n",
      "6 7, 12)\n",
      "10 12)\n",
      "1 4, 12)\n",
      "10 12)\n",
      "6 7, 12)\n",
      "10 12)\n",
      "1 2, 12)\n",
      "16 18)\n",
      "12 1318)\n",
      "16 1813)\n",
      "1 2, 18)\n",
      "16 18)\n",
      "12 1318)\n",
      "16 1813)\n",
      "1 2, 18)\n",
      "10 12)\n",
      "6 7, 12)\n",
      "10 12)\n",
      "1 2, 12)\n",
      "10 12)\n",
      "6 7, 12)\n",
      "10 12)\n",
      "3 4, 12)\n",
      "9 114)\n",
      "5 6 11)\n",
      "9 116)\n",
      "3 4 11)\n",
      "9 114)\n",
      "5 6 11)\n",
      "9 116)\n",
      "1 2 11)\n",
      "14 16)\n",
      "9 10 16)\n",
      "14 160)\n",
      "1 2, 16)\n",
      "14 16)\n",
      "9 10 16)\n",
      "14 160)\n",
      "1 2, 16)\n",
      "9 112)\n",
      "5 7 11)\n",
      "9 117)\n",
      "1 2 11)\n",
      "9 112)\n",
      "5 7 11)\n",
      "9 117)\n",
      "10 111)\n",
      "18 1911)\n",
      "13 1519)\n",
      "18 1915)\n",
      "10 1119)\n",
      "18 1911)\n",
      "13 1519)\n",
      "18 1915)\n",
      "1 5, 19)\n",
      "12 13)\n",
      "8 9, 13)\n",
      "12 13)\n",
      "1 5, 13)\n",
      "12 13)\n",
      "8 9, 13)\n",
      "12 13)\n",
      "1 3, 13)\n",
      "13 15)\n",
      "7 10 15)\n",
      "13 150)\n",
      "1 3, 15)\n",
      "13 15)\n",
      "7 10 15)\n",
      "13 150)\n",
      "1 2, 15)\n",
      "13 15)\n",
      "8 10 15)\n",
      "13 150)\n",
      "1 2, 15)\n",
      "13 15)\n",
      "8 10 15)\n",
      "13 150)\n",
      "1 3, 15)\n",
      "11 14)\n",
      "7 8, 14)\n",
      "11 14)\n",
      "1 3, 14)\n",
      "11 14)\n",
      "7 8, 14)\n",
      "11 14)\n",
      "1 2, 14)\n",
      "(1, 2)\r"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'start' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [83], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m e1_mask, e2_mask \u001b[39m=\u001b[39m tokenizer(sample[\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mspan1_text\u001b[39m\u001b[39m\"\u001b[39m], add_special_tokens\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m], \\\n\u001b[1;32m     10\u001b[0m     tokenizer(sample[\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mspan2_text\u001b[39m\u001b[39m\"\u001b[39m], add_special_tokens\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m] \n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(find_sub_list(e1_mask, result[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]), end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[39mprint\u001b[39m(find_sub_list(e2_mask, result[\u001b[39m\"\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m]), end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [76], line 11\u001b[0m, in \u001b[0;36mfind_sub_list\u001b[0;34m(sublist, main_list)\u001b[0m\n\u001b[1;32m      9\u001b[0m         start \u001b[39m=\u001b[39m idx\n\u001b[1;32m     10\u001b[0m         end \u001b[39m=\u001b[39m idx \u001b[39m+\u001b[39m sublist_length \n\u001b[0;32m---> 11\u001b[0m \u001b[39mprint\u001b[39m(start, end)\n\u001b[1;32m     12\u001b[0m \u001b[39mreturn\u001b[39;00m start, end\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'start' referenced before assignment"
     ]
    }
   ],
   "source": [
    "for sample in dataset[\"train\"]:\n",
    "    result = tokenizer(\n",
    "        sample[\"text\"],\n",
    "        truncation=\"longest_first\",\n",
    "        return_token_type_ids=True,\n",
    "        max_length=245,\n",
    "        )\n",
    "\n",
    "    e1_mask, e2_mask = tokenizer(sample[\"target\"][\"span1_text\"], add_special_tokens=False)[\"input_ids\"], \\\n",
    "        tokenizer(sample[\"target\"][\"span2_text\"], add_special_tokens=False)[\"input_ids\"] \n",
    "    print(find_sub_list(e1_mask, result[\"input_ids\"]), end='\\r')\n",
    "    print(find_sub_list(e2_mask, result[\"input_ids\"]), end='\\r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 64,\n",
       " 'target': {'span1_text': '',\n",
       "  'span2_text': ' ',\n",
       "  'span1_index': 0,\n",
       "  'span2_index': 10},\n",
       " 'label': True,\n",
       " 'text': '      ,  ,       .'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def find_sub_list(sublist: List[str], main_list: List[str]):\n",
    "    sublist_length = len(sublist)\n",
    "    for idx, word in enumerate(main_list):\n",
    "        if word == sublist[0] and main_list[idx:idx+sublist_length] == sublist:\n",
    "            start = idx\n",
    "            end = idx + sublist_length\n",
    "            return start, end\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizer, BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "def process_data(examples, tokenizer: PreTrainedTokenizer, max_length: int):\n",
    "    result = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=\"longest_first\",\n",
    "        return_token_type_ids=True,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    e1_mask = np.zeros_like(result[\"input_ids\"], dtype=int)\n",
    "    e2_mask = np.zeros_like(result[\"input_ids\"], dtype=int)\n",
    "\n",
    "    e1_span = sample[\"target\"][\"span1_text\"]\n",
    "    e2_span = sample[\"target\"][\"span2_text\"]\n",
    "\n",
    "    # Find the start and end indices of the spans in the input text\n",
    "    e1_start, e1_end = find_sub_list(e1_span.split(), examples[\"text\"].split())\n",
    "    e2_start, e2_end = find_sub_list(e2_span.split(), examples[\"text\"].split())\n",
    "\n",
    "        # If the spans are not found, just use the indices of the span words\n",
    "    if e1_start is None:\n",
    "        e1_start, e1_end = [i for i, x in enumerate(examples[\"text\"].split()) if x in e1_span.split()], [i+1 for i, x in enumerate(examples[\"text\"].split()) if x in e1_span.split()]\n",
    "    if e2_start is None:\n",
    "        e2_start, e2_end = [i for i, x in enumerate(examples[\"text\"].split()) if x in e2_span.split()], [i+1 for i, x in enumerate(examples[\"text\"].split()) if x in e2_span.split()]\n",
    "    print(e1_start, e1_end)\n",
    "    print(e2_start, e2_end)\n",
    "    # Set the corresponding mask values to 1 for each span\n",
    "    e1_mask[e1_start:e1_end] = 1\n",
    "    e2_mask[e2_start:e2_end] = 1\n",
    "\n",
    "\n",
    "    result[\"e1_mask\"] = e1_mask\n",
    "    result[\"e2_mask\"] = e2_mask\n",
    "\n",
    "    if isinstance(examples[\"label\"], list):\n",
    "        result[\"labels\"] = [int(x) for x in examples[\"label\"]]\n",
    "    else:\n",
    "        result[\"labels\"] = int(examples[\"label\"])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('cointegrated/rubert-tiny2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {'idx': 64,\n",
    " 'target': {'span1_text': '',\n",
    "  'span2_text': ' ',\n",
    "  'span1_index': 0,\n",
    "  'span2_index': 10},\n",
    " 'label': True,\n",
    " 'text': '      ,  ,       .'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "[10, 13] [11, 14]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m process_data(sample, tokenizer, \u001b[39m255\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [31], line 33\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m(examples, tokenizer, max_length)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m# Set the corresponding mask values to 1 for each span\u001b[39;00m\n\u001b[1;32m     32\u001b[0m e1_mask[e1_start:e1_end] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 33\u001b[0m e2_mask[e2_start:e2_end] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     36\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39me1_mask\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m e1_mask\n\u001b[1;32m     37\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39me2_mask\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m e2_mask\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "process_data(sample, tokenizer, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39131c8ef7df3c93eb396f46fcd465d060882e79e204152730679d38084e79e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

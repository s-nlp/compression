{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f40a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3240d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4090f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from drone import compute_and_save_bert_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff294927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from copy import deepcopy\n",
    "from transformers import AutoModel\n",
    "\n",
    "device = \"cuda:0\"\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226eb8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return {\"input_ids\": self.data[index], \"attention_mask\": torch.ones_like(self.data[index])}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3ab1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.arange(500 * 28).reshape(500, 28) % 97 + 100\n",
    "\n",
    "dataset = TokenizedDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "360ad7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5828b98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘bert_activations’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir bert_activations\n",
    "!rm bert_activations/*.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f93f451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing activations: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "compute_and_save_bert_activations(model, dataloader, output_dir=\"./bert_activations\", device=device, subsample=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66783ce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_0_layer_0_attn-mask.pth\t       batch_2_layer_0_attn-mask.pth\r\n",
      "batch_0_layer_0_attn-out.pth\t       batch_2_layer_0_attn-out.pth\r\n",
      "batch_0_layer_0_embeds.pth\t       batch_2_layer_0_embeds.pth\r\n",
      "batch_0_layer_0_keys.pth\t       batch_2_layer_0_keys.pth\r\n",
      "batch_0_layer_0_mlp-intermediate.pth   batch_2_layer_0_mlp-intermediate.pth\r\n",
      "batch_0_layer_0_mlp-output.pth\t       batch_2_layer_0_mlp-output.pth\r\n",
      "batch_0_layer_0_queries.pth\t       batch_2_layer_0_queries.pth\r\n",
      "batch_0_layer_0_values.pth\t       batch_2_layer_0_values.pth\r\n",
      "batch_0_layer_10_attn-out.pth\t       batch_2_layer_10_attn-out.pth\r\n",
      "batch_0_layer_10_keys.pth\t       batch_2_layer_10_keys.pth\r\n",
      "batch_0_layer_10_mlp-intermediate.pth  batch_2_layer_10_mlp-intermediate.pth\r\n",
      "batch_0_layer_10_mlp-output.pth        batch_2_layer_10_mlp-output.pth\r\n",
      "batch_0_layer_10_queries.pth\t       batch_2_layer_10_queries.pth\r\n",
      "batch_0_layer_10_values.pth\t       batch_2_layer_10_values.pth\r\n",
      "batch_0_layer_11_attn-out.pth\t       batch_2_layer_11_attn-out.pth\r\n",
      "batch_0_layer_11_keys.pth\t       batch_2_layer_11_keys.pth\r\n",
      "batch_0_layer_11_mlp-intermediate.pth  batch_2_layer_11_mlp-intermediate.pth\r\n",
      "batch_0_layer_11_mlp-output.pth        batch_2_layer_11_mlp-output.pth\r\n",
      "batch_0_layer_11_queries.pth\t       batch_2_layer_11_queries.pth\r\n",
      "batch_0_layer_11_values.pth\t       batch_2_layer_11_values.pth\r\n",
      "batch_0_layer_1_attn-out.pth\t       batch_2_layer_1_attn-out.pth\r\n",
      "batch_0_layer_1_keys.pth\t       batch_2_layer_1_keys.pth\r\n",
      "batch_0_layer_1_mlp-intermediate.pth   batch_2_layer_1_mlp-intermediate.pth\r\n",
      "batch_0_layer_1_mlp-output.pth\t       batch_2_layer_1_mlp-output.pth\r\n",
      "batch_0_layer_1_queries.pth\t       batch_2_layer_1_queries.pth\r\n",
      "batch_0_layer_1_values.pth\t       batch_2_layer_1_values.pth\r\n",
      "batch_0_layer_2_attn-out.pth\t       batch_2_layer_2_attn-out.pth\r\n",
      "batch_0_layer_2_keys.pth\t       batch_2_layer_2_keys.pth\r\n",
      "batch_0_layer_2_mlp-intermediate.pth   batch_2_layer_2_mlp-intermediate.pth\r\n",
      "batch_0_layer_2_mlp-output.pth\t       batch_2_layer_2_mlp-output.pth\r\n",
      "batch_0_layer_2_queries.pth\t       batch_2_layer_2_queries.pth\r\n",
      "batch_0_layer_2_values.pth\t       batch_2_layer_2_values.pth\r\n",
      "batch_0_layer_3_attn-out.pth\t       batch_2_layer_3_attn-out.pth\r\n",
      "batch_0_layer_3_keys.pth\t       batch_2_layer_3_keys.pth\r\n",
      "batch_0_layer_3_mlp-intermediate.pth   batch_2_layer_3_mlp-intermediate.pth\r\n",
      "batch_0_layer_3_mlp-output.pth\t       batch_2_layer_3_mlp-output.pth\r\n",
      "batch_0_layer_3_queries.pth\t       batch_2_layer_3_queries.pth\r\n",
      "batch_0_layer_3_values.pth\t       batch_2_layer_3_values.pth\r\n",
      "batch_0_layer_4_attn-out.pth\t       batch_2_layer_4_attn-out.pth\r\n",
      "batch_0_layer_4_keys.pth\t       batch_2_layer_4_keys.pth\r\n",
      "batch_0_layer_4_mlp-intermediate.pth   batch_2_layer_4_mlp-intermediate.pth\r\n",
      "batch_0_layer_4_mlp-output.pth\t       batch_2_layer_4_mlp-output.pth\r\n",
      "batch_0_layer_4_queries.pth\t       batch_2_layer_4_queries.pth\r\n",
      "batch_0_layer_4_values.pth\t       batch_2_layer_4_values.pth\r\n",
      "batch_0_layer_5_attn-out.pth\t       batch_2_layer_5_attn-out.pth\r\n",
      "batch_0_layer_5_keys.pth\t       batch_2_layer_5_keys.pth\r\n",
      "batch_0_layer_5_mlp-intermediate.pth   batch_2_layer_5_mlp-intermediate.pth\r\n",
      "batch_0_layer_5_mlp-output.pth\t       batch_2_layer_5_mlp-output.pth\r\n",
      "batch_0_layer_5_queries.pth\t       batch_2_layer_5_queries.pth\r\n",
      "batch_0_layer_5_values.pth\t       batch_2_layer_5_values.pth\r\n",
      "batch_0_layer_6_attn-out.pth\t       batch_2_layer_6_attn-out.pth\r\n",
      "batch_0_layer_6_keys.pth\t       batch_2_layer_6_keys.pth\r\n",
      "batch_0_layer_6_mlp-intermediate.pth   batch_2_layer_6_mlp-intermediate.pth\r\n",
      "batch_0_layer_6_mlp-output.pth\t       batch_2_layer_6_mlp-output.pth\r\n",
      "batch_0_layer_6_queries.pth\t       batch_2_layer_6_queries.pth\r\n",
      "batch_0_layer_6_values.pth\t       batch_2_layer_6_values.pth\r\n",
      "batch_0_layer_7_attn-out.pth\t       batch_2_layer_7_attn-out.pth\r\n",
      "batch_0_layer_7_keys.pth\t       batch_2_layer_7_keys.pth\r\n",
      "batch_0_layer_7_mlp-intermediate.pth   batch_2_layer_7_mlp-intermediate.pth\r\n",
      "batch_0_layer_7_mlp-output.pth\t       batch_2_layer_7_mlp-output.pth\r\n",
      "batch_0_layer_7_queries.pth\t       batch_2_layer_7_queries.pth\r\n",
      "batch_0_layer_7_values.pth\t       batch_2_layer_7_values.pth\r\n",
      "batch_0_layer_8_attn-out.pth\t       batch_2_layer_8_attn-out.pth\r\n",
      "batch_0_layer_8_keys.pth\t       batch_2_layer_8_keys.pth\r\n",
      "batch_0_layer_8_mlp-intermediate.pth   batch_2_layer_8_mlp-intermediate.pth\r\n",
      "batch_0_layer_8_mlp-output.pth\t       batch_2_layer_8_mlp-output.pth\r\n",
      "batch_0_layer_8_queries.pth\t       batch_2_layer_8_queries.pth\r\n",
      "batch_0_layer_8_values.pth\t       batch_2_layer_8_values.pth\r\n",
      "batch_0_layer_9_attn-out.pth\t       batch_2_layer_9_attn-out.pth\r\n",
      "batch_0_layer_9_keys.pth\t       batch_2_layer_9_keys.pth\r\n",
      "batch_0_layer_9_mlp-intermediate.pth   batch_2_layer_9_mlp-intermediate.pth\r\n",
      "batch_0_layer_9_mlp-output.pth\t       batch_2_layer_9_mlp-output.pth\r\n",
      "batch_0_layer_9_queries.pth\t       batch_2_layer_9_queries.pth\r\n",
      "batch_0_layer_9_values.pth\t       batch_2_layer_9_values.pth\r\n",
      "batch_1_layer_0_attn-mask.pth\t       batch_3_layer_0_attn-mask.pth\r\n",
      "batch_1_layer_0_attn-out.pth\t       batch_3_layer_0_attn-out.pth\r\n",
      "batch_1_layer_0_embeds.pth\t       batch_3_layer_0_embeds.pth\r\n",
      "batch_1_layer_0_keys.pth\t       batch_3_layer_0_keys.pth\r\n",
      "batch_1_layer_0_mlp-intermediate.pth   batch_3_layer_0_mlp-intermediate.pth\r\n",
      "batch_1_layer_0_mlp-output.pth\t       batch_3_layer_0_mlp-output.pth\r\n",
      "batch_1_layer_0_queries.pth\t       batch_3_layer_0_queries.pth\r\n",
      "batch_1_layer_0_values.pth\t       batch_3_layer_0_values.pth\r\n",
      "batch_1_layer_10_attn-out.pth\t       batch_3_layer_10_attn-out.pth\r\n",
      "batch_1_layer_10_keys.pth\t       batch_3_layer_10_keys.pth\r\n",
      "batch_1_layer_10_mlp-intermediate.pth  batch_3_layer_10_mlp-intermediate.pth\r\n",
      "batch_1_layer_10_mlp-output.pth        batch_3_layer_10_mlp-output.pth\r\n",
      "batch_1_layer_10_queries.pth\t       batch_3_layer_10_queries.pth\r\n",
      "batch_1_layer_10_values.pth\t       batch_3_layer_10_values.pth\r\n",
      "batch_1_layer_11_attn-out.pth\t       batch_3_layer_11_attn-out.pth\r\n",
      "batch_1_layer_11_keys.pth\t       batch_3_layer_11_keys.pth\r\n",
      "batch_1_layer_11_mlp-intermediate.pth  batch_3_layer_11_mlp-intermediate.pth\r\n",
      "batch_1_layer_11_mlp-output.pth        batch_3_layer_11_mlp-output.pth\r\n",
      "batch_1_layer_11_queries.pth\t       batch_3_layer_11_queries.pth\r\n",
      "batch_1_layer_11_values.pth\t       batch_3_layer_11_values.pth\r\n",
      "batch_1_layer_1_attn-out.pth\t       batch_3_layer_1_attn-out.pth\r\n",
      "batch_1_layer_1_keys.pth\t       batch_3_layer_1_keys.pth\r\n",
      "batch_1_layer_1_mlp-intermediate.pth   batch_3_layer_1_mlp-intermediate.pth\r\n",
      "batch_1_layer_1_mlp-output.pth\t       batch_3_layer_1_mlp-output.pth\r\n",
      "batch_1_layer_1_queries.pth\t       batch_3_layer_1_queries.pth\r\n",
      "batch_1_layer_1_values.pth\t       batch_3_layer_1_values.pth\r\n",
      "batch_1_layer_2_attn-out.pth\t       batch_3_layer_2_attn-out.pth\r\n",
      "batch_1_layer_2_keys.pth\t       batch_3_layer_2_keys.pth\r\n",
      "batch_1_layer_2_mlp-intermediate.pth   batch_3_layer_2_mlp-intermediate.pth\r\n",
      "batch_1_layer_2_mlp-output.pth\t       batch_3_layer_2_mlp-output.pth\r\n",
      "batch_1_layer_2_queries.pth\t       batch_3_layer_2_queries.pth\r\n",
      "batch_1_layer_2_values.pth\t       batch_3_layer_2_values.pth\r\n",
      "batch_1_layer_3_attn-out.pth\t       batch_3_layer_3_attn-out.pth\r\n",
      "batch_1_layer_3_keys.pth\t       batch_3_layer_3_keys.pth\r\n",
      "batch_1_layer_3_mlp-intermediate.pth   batch_3_layer_3_mlp-intermediate.pth\r\n",
      "batch_1_layer_3_mlp-output.pth\t       batch_3_layer_3_mlp-output.pth\r\n",
      "batch_1_layer_3_queries.pth\t       batch_3_layer_3_queries.pth\r\n",
      "batch_1_layer_3_values.pth\t       batch_3_layer_3_values.pth\r\n",
      "batch_1_layer_4_attn-out.pth\t       batch_3_layer_4_attn-out.pth\r\n",
      "batch_1_layer_4_keys.pth\t       batch_3_layer_4_keys.pth\r\n",
      "batch_1_layer_4_mlp-intermediate.pth   batch_3_layer_4_mlp-intermediate.pth\r\n",
      "batch_1_layer_4_mlp-output.pth\t       batch_3_layer_4_mlp-output.pth\r\n",
      "batch_1_layer_4_queries.pth\t       batch_3_layer_4_queries.pth\r\n",
      "batch_1_layer_4_values.pth\t       batch_3_layer_4_values.pth\r\n",
      "batch_1_layer_5_attn-out.pth\t       batch_3_layer_5_attn-out.pth\r\n",
      "batch_1_layer_5_keys.pth\t       batch_3_layer_5_keys.pth\r\n",
      "batch_1_layer_5_mlp-intermediate.pth   batch_3_layer_5_mlp-intermediate.pth\r\n",
      "batch_1_layer_5_mlp-output.pth\t       batch_3_layer_5_mlp-output.pth\r\n",
      "batch_1_layer_5_queries.pth\t       batch_3_layer_5_queries.pth\r\n",
      "batch_1_layer_5_values.pth\t       batch_3_layer_5_values.pth\r\n",
      "batch_1_layer_6_attn-out.pth\t       batch_3_layer_6_attn-out.pth\r\n",
      "batch_1_layer_6_keys.pth\t       batch_3_layer_6_keys.pth\r\n",
      "batch_1_layer_6_mlp-intermediate.pth   batch_3_layer_6_mlp-intermediate.pth\r\n",
      "batch_1_layer_6_mlp-output.pth\t       batch_3_layer_6_mlp-output.pth\r\n",
      "batch_1_layer_6_queries.pth\t       batch_3_layer_6_queries.pth\r\n",
      "batch_1_layer_6_values.pth\t       batch_3_layer_6_values.pth\r\n",
      "batch_1_layer_7_attn-out.pth\t       batch_3_layer_7_attn-out.pth\r\n",
      "batch_1_layer_7_keys.pth\t       batch_3_layer_7_keys.pth\r\n",
      "batch_1_layer_7_mlp-intermediate.pth   batch_3_layer_7_mlp-intermediate.pth\r\n",
      "batch_1_layer_7_mlp-output.pth\t       batch_3_layer_7_mlp-output.pth\r\n",
      "batch_1_layer_7_queries.pth\t       batch_3_layer_7_queries.pth\r\n",
      "batch_1_layer_7_values.pth\t       batch_3_layer_7_values.pth\r\n",
      "batch_1_layer_8_attn-out.pth\t       batch_3_layer_8_attn-out.pth\r\n",
      "batch_1_layer_8_keys.pth\t       batch_3_layer_8_keys.pth\r\n",
      "batch_1_layer_8_mlp-intermediate.pth   batch_3_layer_8_mlp-intermediate.pth\r\n",
      "batch_1_layer_8_mlp-output.pth\t       batch_3_layer_8_mlp-output.pth\r\n",
      "batch_1_layer_8_queries.pth\t       batch_3_layer_8_queries.pth\r\n",
      "batch_1_layer_8_values.pth\t       batch_3_layer_8_values.pth\r\n",
      "batch_1_layer_9_attn-out.pth\t       batch_3_layer_9_attn-out.pth\r\n",
      "batch_1_layer_9_keys.pth\t       batch_3_layer_9_keys.pth\r\n",
      "batch_1_layer_9_mlp-intermediate.pth   batch_3_layer_9_mlp-intermediate.pth\r\n",
      "batch_1_layer_9_mlp-output.pth\t       batch_3_layer_9_mlp-output.pth\r\n",
      "batch_1_layer_9_queries.pth\t       batch_3_layer_9_queries.pth\r\n",
      "batch_1_layer_9_values.pth\t       batch_3_layer_9_values.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls bert_activations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7708b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from drone import concat_activations_by_layers\n",
    "\n",
    "concat_activations_by_layers(\"./bert_activations/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c725e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_0_layer_0_attn-mask.pth\t       batch_2_layer_3_values.pth\r\n",
      "batch_0_layer_0_attn-out.pth\t       batch_2_layer_4_attn-out.pth\r\n",
      "batch_0_layer_0_embeds.pth\t       batch_2_layer_4_keys.pth\r\n",
      "batch_0_layer_0_keys.pth\t       batch_2_layer_4_mlp-intermediate.pth\r\n",
      "batch_0_layer_0_mlp-intermediate.pth   batch_2_layer_4_mlp-output.pth\r\n",
      "batch_0_layer_0_mlp-output.pth\t       batch_2_layer_4_queries.pth\r\n",
      "batch_0_layer_0_queries.pth\t       batch_2_layer_4_values.pth\r\n",
      "batch_0_layer_0_values.pth\t       batch_2_layer_5_attn-out.pth\r\n",
      "batch_0_layer_10_attn-out.pth\t       batch_2_layer_5_keys.pth\r\n",
      "batch_0_layer_10_keys.pth\t       batch_2_layer_5_mlp-intermediate.pth\r\n",
      "batch_0_layer_10_mlp-intermediate.pth  batch_2_layer_5_mlp-output.pth\r\n",
      "batch_0_layer_10_mlp-output.pth        batch_2_layer_5_queries.pth\r\n",
      "batch_0_layer_10_queries.pth\t       batch_2_layer_5_values.pth\r\n",
      "batch_0_layer_10_values.pth\t       batch_2_layer_6_attn-out.pth\r\n",
      "batch_0_layer_11_attn-out.pth\t       batch_2_layer_6_keys.pth\r\n",
      "batch_0_layer_11_keys.pth\t       batch_2_layer_6_mlp-intermediate.pth\r\n",
      "batch_0_layer_11_mlp-intermediate.pth  batch_2_layer_6_mlp-output.pth\r\n",
      "batch_0_layer_11_mlp-output.pth        batch_2_layer_6_queries.pth\r\n",
      "batch_0_layer_11_queries.pth\t       batch_2_layer_6_values.pth\r\n",
      "batch_0_layer_11_values.pth\t       batch_2_layer_7_attn-out.pth\r\n",
      "batch_0_layer_1_attn-out.pth\t       batch_2_layer_7_keys.pth\r\n",
      "batch_0_layer_1_keys.pth\t       batch_2_layer_7_mlp-intermediate.pth\r\n",
      "batch_0_layer_1_mlp-intermediate.pth   batch_2_layer_7_mlp-output.pth\r\n",
      "batch_0_layer_1_mlp-output.pth\t       batch_2_layer_7_queries.pth\r\n",
      "batch_0_layer_1_queries.pth\t       batch_2_layer_7_values.pth\r\n",
      "batch_0_layer_1_values.pth\t       batch_2_layer_8_attn-out.pth\r\n",
      "batch_0_layer_2_attn-out.pth\t       batch_2_layer_8_keys.pth\r\n",
      "batch_0_layer_2_keys.pth\t       batch_2_layer_8_mlp-intermediate.pth\r\n",
      "batch_0_layer_2_mlp-intermediate.pth   batch_2_layer_8_mlp-output.pth\r\n",
      "batch_0_layer_2_mlp-output.pth\t       batch_2_layer_8_queries.pth\r\n",
      "batch_0_layer_2_queries.pth\t       batch_2_layer_8_values.pth\r\n",
      "batch_0_layer_2_values.pth\t       batch_2_layer_9_attn-out.pth\r\n",
      "batch_0_layer_3_attn-out.pth\t       batch_2_layer_9_keys.pth\r\n",
      "batch_0_layer_3_keys.pth\t       batch_2_layer_9_mlp-intermediate.pth\r\n",
      "batch_0_layer_3_mlp-intermediate.pth   batch_2_layer_9_mlp-output.pth\r\n",
      "batch_0_layer_3_mlp-output.pth\t       batch_2_layer_9_queries.pth\r\n",
      "batch_0_layer_3_queries.pth\t       batch_2_layer_9_values.pth\r\n",
      "batch_0_layer_3_values.pth\t       batch_3_layer_0_attn-mask.pth\r\n",
      "batch_0_layer_4_attn-out.pth\t       batch_3_layer_0_attn-out.pth\r\n",
      "batch_0_layer_4_keys.pth\t       batch_3_layer_0_embeds.pth\r\n",
      "batch_0_layer_4_mlp-intermediate.pth   batch_3_layer_0_keys.pth\r\n",
      "batch_0_layer_4_mlp-output.pth\t       batch_3_layer_0_mlp-intermediate.pth\r\n",
      "batch_0_layer_4_queries.pth\t       batch_3_layer_0_mlp-output.pth\r\n",
      "batch_0_layer_4_values.pth\t       batch_3_layer_0_queries.pth\r\n",
      "batch_0_layer_5_attn-out.pth\t       batch_3_layer_0_values.pth\r\n",
      "batch_0_layer_5_keys.pth\t       batch_3_layer_10_attn-out.pth\r\n",
      "batch_0_layer_5_mlp-intermediate.pth   batch_3_layer_10_keys.pth\r\n",
      "batch_0_layer_5_mlp-output.pth\t       batch_3_layer_10_mlp-intermediate.pth\r\n",
      "batch_0_layer_5_queries.pth\t       batch_3_layer_10_mlp-output.pth\r\n",
      "batch_0_layer_5_values.pth\t       batch_3_layer_10_queries.pth\r\n",
      "batch_0_layer_6_attn-out.pth\t       batch_3_layer_10_values.pth\r\n",
      "batch_0_layer_6_keys.pth\t       batch_3_layer_11_attn-out.pth\r\n",
      "batch_0_layer_6_mlp-intermediate.pth   batch_3_layer_11_keys.pth\r\n",
      "batch_0_layer_6_mlp-output.pth\t       batch_3_layer_11_mlp-intermediate.pth\r\n",
      "batch_0_layer_6_queries.pth\t       batch_3_layer_11_mlp-output.pth\r\n",
      "batch_0_layer_6_values.pth\t       batch_3_layer_11_queries.pth\r\n",
      "batch_0_layer_7_attn-out.pth\t       batch_3_layer_11_values.pth\r\n",
      "batch_0_layer_7_keys.pth\t       batch_3_layer_1_attn-out.pth\r\n",
      "batch_0_layer_7_mlp-intermediate.pth   batch_3_layer_1_keys.pth\r\n",
      "batch_0_layer_7_mlp-output.pth\t       batch_3_layer_1_mlp-intermediate.pth\r\n",
      "batch_0_layer_7_queries.pth\t       batch_3_layer_1_mlp-output.pth\r\n",
      "batch_0_layer_7_values.pth\t       batch_3_layer_1_queries.pth\r\n",
      "batch_0_layer_8_attn-out.pth\t       batch_3_layer_1_values.pth\r\n",
      "batch_0_layer_8_keys.pth\t       batch_3_layer_2_attn-out.pth\r\n",
      "batch_0_layer_8_mlp-intermediate.pth   batch_3_layer_2_keys.pth\r\n",
      "batch_0_layer_8_mlp-output.pth\t       batch_3_layer_2_mlp-intermediate.pth\r\n",
      "batch_0_layer_8_queries.pth\t       batch_3_layer_2_mlp-output.pth\r\n",
      "batch_0_layer_8_values.pth\t       batch_3_layer_2_queries.pth\r\n",
      "batch_0_layer_9_attn-out.pth\t       batch_3_layer_2_values.pth\r\n",
      "batch_0_layer_9_keys.pth\t       batch_3_layer_3_attn-out.pth\r\n",
      "batch_0_layer_9_mlp-intermediate.pth   batch_3_layer_3_keys.pth\r\n",
      "batch_0_layer_9_mlp-output.pth\t       batch_3_layer_3_mlp-intermediate.pth\r\n",
      "batch_0_layer_9_queries.pth\t       batch_3_layer_3_mlp-output.pth\r\n",
      "batch_0_layer_9_values.pth\t       batch_3_layer_3_queries.pth\r\n",
      "batch_1_layer_0_attn-mask.pth\t       batch_3_layer_3_values.pth\r\n",
      "batch_1_layer_0_attn-out.pth\t       batch_3_layer_4_attn-out.pth\r\n",
      "batch_1_layer_0_embeds.pth\t       batch_3_layer_4_keys.pth\r\n",
      "batch_1_layer_0_keys.pth\t       batch_3_layer_4_mlp-intermediate.pth\r\n",
      "batch_1_layer_0_mlp-intermediate.pth   batch_3_layer_4_mlp-output.pth\r\n",
      "batch_1_layer_0_mlp-output.pth\t       batch_3_layer_4_queries.pth\r\n",
      "batch_1_layer_0_queries.pth\t       batch_3_layer_4_values.pth\r\n",
      "batch_1_layer_0_values.pth\t       batch_3_layer_5_attn-out.pth\r\n",
      "batch_1_layer_10_attn-out.pth\t       batch_3_layer_5_keys.pth\r\n",
      "batch_1_layer_10_keys.pth\t       batch_3_layer_5_mlp-intermediate.pth\r\n",
      "batch_1_layer_10_mlp-intermediate.pth  batch_3_layer_5_mlp-output.pth\r\n",
      "batch_1_layer_10_mlp-output.pth        batch_3_layer_5_queries.pth\r\n",
      "batch_1_layer_10_queries.pth\t       batch_3_layer_5_values.pth\r\n",
      "batch_1_layer_10_values.pth\t       batch_3_layer_6_attn-out.pth\r\n",
      "batch_1_layer_11_attn-out.pth\t       batch_3_layer_6_keys.pth\r\n",
      "batch_1_layer_11_keys.pth\t       batch_3_layer_6_mlp-intermediate.pth\r\n",
      "batch_1_layer_11_mlp-intermediate.pth  batch_3_layer_6_mlp-output.pth\r\n",
      "batch_1_layer_11_mlp-output.pth        batch_3_layer_6_queries.pth\r\n",
      "batch_1_layer_11_queries.pth\t       batch_3_layer_6_values.pth\r\n",
      "batch_1_layer_11_values.pth\t       batch_3_layer_7_attn-out.pth\r\n",
      "batch_1_layer_1_attn-out.pth\t       batch_3_layer_7_keys.pth\r\n",
      "batch_1_layer_1_keys.pth\t       batch_3_layer_7_mlp-intermediate.pth\r\n",
      "batch_1_layer_1_mlp-intermediate.pth   batch_3_layer_7_mlp-output.pth\r\n",
      "batch_1_layer_1_mlp-output.pth\t       batch_3_layer_7_queries.pth\r\n",
      "batch_1_layer_1_queries.pth\t       batch_3_layer_7_values.pth\r\n",
      "batch_1_layer_1_values.pth\t       batch_3_layer_8_attn-out.pth\r\n",
      "batch_1_layer_2_attn-out.pth\t       batch_3_layer_8_keys.pth\r\n",
      "batch_1_layer_2_keys.pth\t       batch_3_layer_8_mlp-intermediate.pth\r\n",
      "batch_1_layer_2_mlp-intermediate.pth   batch_3_layer_8_mlp-output.pth\r\n",
      "batch_1_layer_2_mlp-output.pth\t       batch_3_layer_8_queries.pth\r\n",
      "batch_1_layer_2_queries.pth\t       batch_3_layer_8_values.pth\r\n",
      "batch_1_layer_2_values.pth\t       batch_3_layer_9_attn-out.pth\r\n",
      "batch_1_layer_3_attn-out.pth\t       batch_3_layer_9_keys.pth\r\n",
      "batch_1_layer_3_keys.pth\t       batch_3_layer_9_mlp-intermediate.pth\r\n",
      "batch_1_layer_3_mlp-intermediate.pth   batch_3_layer_9_mlp-output.pth\r\n",
      "batch_1_layer_3_mlp-output.pth\t       batch_3_layer_9_queries.pth\r\n",
      "batch_1_layer_3_queries.pth\t       batch_3_layer_9_values.pth\r\n",
      "batch_1_layer_3_values.pth\t       layer_0_attn-mask.pth\r\n",
      "batch_1_layer_4_attn-out.pth\t       layer_0_attn-out.pth\r\n",
      "batch_1_layer_4_keys.pth\t       layer_0_embeds.pth\r\n",
      "batch_1_layer_4_mlp-intermediate.pth   layer_0_keys.pth\r\n",
      "batch_1_layer_4_mlp-output.pth\t       layer_0_mlp-intermediate.pth\r\n",
      "batch_1_layer_4_queries.pth\t       layer_0_mlp-output.pth\r\n",
      "batch_1_layer_4_values.pth\t       layer_0_queries.pth\r\n",
      "batch_1_layer_5_attn-out.pth\t       layer_0_values.pth\r\n",
      "batch_1_layer_5_keys.pth\t       layer_10_attn-out.pth\r\n",
      "batch_1_layer_5_mlp-intermediate.pth   layer_10_keys.pth\r\n",
      "batch_1_layer_5_mlp-output.pth\t       layer_10_mlp-intermediate.pth\r\n",
      "batch_1_layer_5_queries.pth\t       layer_10_mlp-output.pth\r\n",
      "batch_1_layer_5_values.pth\t       layer_10_queries.pth\r\n",
      "batch_1_layer_6_attn-out.pth\t       layer_10_values.pth\r\n",
      "batch_1_layer_6_keys.pth\t       layer_11_attn-out.pth\r\n",
      "batch_1_layer_6_mlp-intermediate.pth   layer_11_keys.pth\r\n",
      "batch_1_layer_6_mlp-output.pth\t       layer_11_mlp-intermediate.pth\r\n",
      "batch_1_layer_6_queries.pth\t       layer_11_mlp-output.pth\r\n",
      "batch_1_layer_6_values.pth\t       layer_11_queries.pth\r\n",
      "batch_1_layer_7_attn-out.pth\t       layer_11_values.pth\r\n",
      "batch_1_layer_7_keys.pth\t       layer_1_attn-out.pth\r\n",
      "batch_1_layer_7_mlp-intermediate.pth   layer_1_keys.pth\r\n",
      "batch_1_layer_7_mlp-output.pth\t       layer_1_mlp-intermediate.pth\r\n",
      "batch_1_layer_7_queries.pth\t       layer_1_mlp-output.pth\r\n",
      "batch_1_layer_7_values.pth\t       layer_1_queries.pth\r\n",
      "batch_1_layer_8_attn-out.pth\t       layer_1_values.pth\r\n",
      "batch_1_layer_8_keys.pth\t       layer_2_attn-out.pth\r\n",
      "batch_1_layer_8_mlp-intermediate.pth   layer_2_keys.pth\r\n",
      "batch_1_layer_8_mlp-output.pth\t       layer_2_mlp-intermediate.pth\r\n",
      "batch_1_layer_8_queries.pth\t       layer_2_mlp-output.pth\r\n",
      "batch_1_layer_8_values.pth\t       layer_2_queries.pth\r\n",
      "batch_1_layer_9_attn-out.pth\t       layer_2_values.pth\r\n",
      "batch_1_layer_9_keys.pth\t       layer_3_attn-out.pth\r\n",
      "batch_1_layer_9_mlp-intermediate.pth   layer_3_keys.pth\r\n",
      "batch_1_layer_9_mlp-output.pth\t       layer_3_mlp-intermediate.pth\r\n",
      "batch_1_layer_9_queries.pth\t       layer_3_mlp-output.pth\r\n",
      "batch_1_layer_9_values.pth\t       layer_3_queries.pth\r\n",
      "batch_2_layer_0_attn-mask.pth\t       layer_3_values.pth\r\n",
      "batch_2_layer_0_attn-out.pth\t       layer_4_attn-out.pth\r\n",
      "batch_2_layer_0_embeds.pth\t       layer_4_keys.pth\r\n",
      "batch_2_layer_0_keys.pth\t       layer_4_mlp-intermediate.pth\r\n",
      "batch_2_layer_0_mlp-intermediate.pth   layer_4_mlp-output.pth\r\n",
      "batch_2_layer_0_mlp-output.pth\t       layer_4_queries.pth\r\n",
      "batch_2_layer_0_queries.pth\t       layer_4_values.pth\r\n",
      "batch_2_layer_0_values.pth\t       layer_5_attn-out.pth\r\n",
      "batch_2_layer_10_attn-out.pth\t       layer_5_keys.pth\r\n",
      "batch_2_layer_10_keys.pth\t       layer_5_mlp-intermediate.pth\r\n",
      "batch_2_layer_10_mlp-intermediate.pth  layer_5_mlp-output.pth\r\n",
      "batch_2_layer_10_mlp-output.pth        layer_5_queries.pth\r\n",
      "batch_2_layer_10_queries.pth\t       layer_5_values.pth\r\n",
      "batch_2_layer_10_values.pth\t       layer_6_attn-out.pth\r\n",
      "batch_2_layer_11_attn-out.pth\t       layer_6_keys.pth\r\n",
      "batch_2_layer_11_keys.pth\t       layer_6_mlp-intermediate.pth\r\n",
      "batch_2_layer_11_mlp-intermediate.pth  layer_6_mlp-output.pth\r\n",
      "batch_2_layer_11_mlp-output.pth        layer_6_queries.pth\r\n",
      "batch_2_layer_11_queries.pth\t       layer_6_values.pth\r\n",
      "batch_2_layer_11_values.pth\t       layer_7_attn-out.pth\r\n",
      "batch_2_layer_1_attn-out.pth\t       layer_7_keys.pth\r\n",
      "batch_2_layer_1_keys.pth\t       layer_7_mlp-intermediate.pth\r\n",
      "batch_2_layer_1_mlp-intermediate.pth   layer_7_mlp-output.pth\r\n",
      "batch_2_layer_1_mlp-output.pth\t       layer_7_queries.pth\r\n",
      "batch_2_layer_1_queries.pth\t       layer_7_values.pth\r\n",
      "batch_2_layer_1_values.pth\t       layer_8_attn-out.pth\r\n",
      "batch_2_layer_2_attn-out.pth\t       layer_8_keys.pth\r\n",
      "batch_2_layer_2_keys.pth\t       layer_8_mlp-intermediate.pth\r\n",
      "batch_2_layer_2_mlp-intermediate.pth   layer_8_mlp-output.pth\r\n",
      "batch_2_layer_2_mlp-output.pth\t       layer_8_queries.pth\r\n",
      "batch_2_layer_2_queries.pth\t       layer_8_values.pth\r\n",
      "batch_2_layer_2_values.pth\t       layer_9_attn-out.pth\r\n",
      "batch_2_layer_3_attn-out.pth\t       layer_9_keys.pth\r\n",
      "batch_2_layer_3_keys.pth\t       layer_9_mlp-intermediate.pth\r\n",
      "batch_2_layer_3_mlp-intermediate.pth   layer_9_mlp-output.pth\r\n",
      "batch_2_layer_3_mlp-output.pth\t       layer_9_queries.pth\r\n",
      "batch_2_layer_3_queries.pth\t       layer_9_values.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls bert_activations/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "959c56ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error: 2.4758108571683106\n",
      "Relative error: 1.4365284705374777\n",
      "Relative error: 1.4476874611829198\n",
      "Relative error: 0.6711083809911085\n",
      "Relative error: 0.8354931261727883\n",
      "Relative error: 120.35973890625857\n",
      "Relative error: 67.09788560879295\n",
      "Relative error: 54.797522223862856\n",
      "Relative error: 153.67660941360057\n",
      "Relative error: 3.364251157350531\n",
      "Relative error: 0.9953075481532908\n",
      "Relative error: 7.88361819425119\n",
      "Relative error: 0.8870916649548979\n",
      "Relative error: 1.0244650358474787\n",
      "Relative error: 0.9661249307555151\n",
      "Relative error: 0.58574131768592\n",
      "Relative error: 0.24868560647445295\n",
      "Relative error: 10.025016196711704\n",
      "Relative error: 0.6380854711827554\n",
      "Relative error: 0.8028771896215232\n",
      "Relative error: 0.7023145738453228\n",
      "Relative error: 0.5683557680394715\n",
      "Relative error: 0.24256982922778922\n",
      "Relative error: 3.9076505350091595\n",
      "Relative error: 0.4440861980940897\n",
      "Relative error: 0.6097666038098561\n",
      "Relative error: 0.38583672584089695\n",
      "Relative error: 0.562466175795647\n",
      "Relative error: 0.26303138043910906\n",
      "Relative error: 5.789145850642455\n",
      "Relative error: 0.47462203382183155\n",
      "Relative error: 0.6153696688090511\n",
      "Relative error: 0.5614671005524877\n",
      "Relative error: 0.5320101430550338\n",
      "Relative error: 0.20606787972835552\n",
      "Relative error: 4.066398474571725\n",
      "Relative error: 0.43898760349880844\n",
      "Relative error: 0.5710212528589135\n",
      "Relative error: 0.4399872253424339\n",
      "Relative error: 0.538652903732903\n",
      "Relative error: 0.22671991072226153\n",
      "Relative error: 12.99076543680715\n",
      "Relative error: 0.48388045321743695\n",
      "Relative error: 0.8072118536955153\n",
      "Relative error: 0.5496367475856259\n",
      "Relative error: 0.5485351548132343\n",
      "Relative error: 0.22827324504087024\n",
      "Relative error: 1.672050116045777\n",
      "Relative error: 0.41371152879900097\n",
      "Relative error: 0.5293105348613959\n",
      "Relative error: 0.4382736170852191\n",
      "Relative error: 0.3405013399825981\n",
      "Relative error: 0.21018142557583805\n",
      "Relative error: 2.0603716146756508\n",
      "Relative error: 0.3207686168461267\n",
      "Relative error: 0.43246177458527196\n",
      "Relative error: 0.37000892184288087\n",
      "Relative error: 0.7823370329574085\n",
      "Relative error: 0.20157225256038036\n",
      "Relative error: 91.68272638585312\n",
      "Relative error: 6.2118682064813004\n",
      "Relative error: 4.907219873166315\n",
      "Relative error: 4.567778996645407\n",
      "Relative error: 0.6375457930553428\n",
      "Relative error: 2.5324168988307267\n",
      "Relative error: 18.094036096720078\n",
      "Relative error: 5.882261166249727\n",
      "Relative error: 4.919629979924911\n",
      "Relative error: 8.597278165708914\n",
      "Relative error: 0.8528802189242745\n",
      "Relative error: 0.4789603435373158\n",
      "Relative error: 7.668978433745733\n"
     ]
    }
   ],
   "source": [
    "from drone import run_drone_compression_for_bert\n",
    "\n",
    "compressed_model = run_drone_compression_for_bert(deepcopy(model), 300, \"bert_activations\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b0320a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8086930365468491"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "count_params(compressed_model) / count_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66066db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2Model(\n",
       "  (embeddings): DebertaV2Embeddings(\n",
       "    (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (encoder): DebertaV2Encoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): LowRankLinear(768_300_768)\n",
       "            (key_proj): LowRankLinear(768_300_768)\n",
       "            (value_proj): LowRankLinear(768_300_768)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): LowRankLinear(768_300_768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): LowRankLinear(768_300_3072)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): LowRankLinear(3072_300_768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (1): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): LowRankLinear(768_300_768)\n",
       "            (key_proj): LowRankLinear(768_300_768)\n",
       "            (value_proj): LowRankLinear(768_300_768)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): LowRankLinear(768_300_768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): LowRankLinear(768_300_3072)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): LowRankLinear(3072_300_768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (2): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): LowRankLinear(768_300_768)\n",
       "            (key_proj): LowRankLinear(768_300_768)\n",
       "            (value_proj): LowRankLinear(768_300_768)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): LowRankLinear(768_300_768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): LowRankLinear(768_300_3072)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): LowRankLinear(3072_300_768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (3): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): LowRankLinear(768_300_768)\n",
       "            (key_proj): LowRankLinear(768_300_768)\n",
       "            (value_proj): LowRankLinear(768_300_768)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): LowRankLinear(768_300_768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): LowRankLinear(768_300_3072)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): LowRankLinear(3072_300_768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (4): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): LowRankLinear(768_300_768)\n",
       "            (key_proj): LowRankLinear(768_300_768)\n",
       "            (value_proj): LowRankLinear(768_300_768)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): LowRankLinear(768_300_768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): LowRankLinear(768_300_3072)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): LowRankLinear(3072_300_768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (5): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): LowRankLinear(768_300_768)\n",
       "            (key_proj): LowRankLinear(768_300_768)\n",
       "            (value_proj): LowRankLinear(768_300_768)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): LowRankLinear(768_300_768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): LowRankLinear(768_300_3072)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): LowRankLinear(3072_300_768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (6): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): LowRankLinear(768_300_768)\n",
       "            (key_proj): LowRankLinear(768_300_768)\n",
       "            (value_proj): LowRankLinear(768_300_768)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): LowRankLinear(768_300_768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): LowRankLinear(768_300_3072)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): LowRankLinear(3072_300_768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (7): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): LowRankLinear(768_300_768)\n",
       "            (key_proj): LowRankLinear(768_300_768)\n",
       "            (value_proj): LowRankLinear(768_300_768)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): LowRankLinear(768_300_768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): LowRankLinear(768_300_3072)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): LowRankLinear(3072_300_768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (8): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): LowRankLinear(768_300_768)\n",
       "            (key_proj): LowRankLinear(768_300_768)\n",
       "            (value_proj): LowRankLinear(768_300_768)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): LowRankLinear(768_300_768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): LowRankLinear(768_300_3072)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): LowRankLinear(3072_300_768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (9): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): LowRankLinear(768_300_768)\n",
       "            (key_proj): LowRankLinear(768_300_768)\n",
       "            (value_proj): LowRankLinear(768_300_768)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): LowRankLinear(768_300_768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): LowRankLinear(768_300_3072)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): LowRankLinear(3072_300_768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (10): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): LowRankLinear(768_300_768)\n",
       "            (key_proj): LowRankLinear(768_300_768)\n",
       "            (value_proj): LowRankLinear(768_300_768)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): LowRankLinear(768_300_768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): LowRankLinear(768_300_3072)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): LowRankLinear(3072_300_768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (11): DebertaV2Layer(\n",
       "        (attention): DebertaV2Attention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query_proj): LowRankLinear(768_300_768)\n",
       "            (key_proj): LowRankLinear(768_300_768)\n",
       "            (value_proj): LowRankLinear(768_300_768)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaV2SelfOutput(\n",
       "            (dense): LowRankLinear(768_300_768)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaV2Intermediate(\n",
       "          (dense): LowRankLinear(768_300_3072)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaV2Output(\n",
       "          (dense): LowRankLinear(3072_300_768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rel_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f6520c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5884309108231023"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(compressed_model.encoder) / count_params(model.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e14aa81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    break\n",
    "\n",
    "with torch.inference_mode():\n",
    "    output = model(**batch, output_hidden_states=True)\n",
    "\n",
    "    embeds = model.embeddings(batch[\"input_ids\"])\n",
    "    other_output = model.encoder(embeds, torch.ones_like(batch[\"input_ids\"]))\n",
    "\n",
    "    print(torch.allclose(output.last_hidden_state, output.hidden_states[-1]))\n",
    "    print(torch.allclose(output.hidden_states[0], embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ce7788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

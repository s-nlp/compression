{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaHhHqawgO33"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjRNqQVJP3YI"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%cd transformers\n",
        "!pip install .\n",
        "#!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFlfvedQP54H"
      },
      "outputs": [],
      "source": [
        "!pip install -r ./examples/pytorch/text-classification/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPU5V_tCP5-W"
      },
      "outputs": [],
      "source": [
        "# When installing in editable mode, `transformers` is not recognized as a package.\n",
        "# this line must be added in order for python to be aware of transformers.\n",
        "#RUN cd transformers && python3 setup.py develop\n",
        "#%cd /content/transformers \n",
        "!python setup.py develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8M9dMC_gP8H",
        "outputId": "ce134cfd-7edd-40bc-94d4-4c3a076c901f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8o4gL31fuMI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "n_layers, n_heads = model.config.num_hidden_layers, model.config.num_attention_heads\n",
        "head_mask = (torch.randint(0,101,(n_layers, n_heads)) > 50) *1\n",
        "\n",
        "#we need at least one alive head at layer\n",
        "for i in np.where(np.all(np.isclose(head_mask, 0), axis=1))[0]:\n",
        "    head_mask[i][0] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw78N2GImgME",
        "outputId": "64d325c7-477e-491c-cc26-5d614b4a2b2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0],\n",
              "        [0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n",
              "        [1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1],\n",
              "        [0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
              "        [0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1],\n",
              "        [0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0],\n",
              "        [0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1],\n",
              "        [1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0],\n",
              "        [1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1],\n",
              "        [1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0]])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "head_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYjtG3nnmNN9",
        "outputId": "375c5c10-042d-4ef1-af21-f62e3487b590"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: [1, 4, 6, 7, 10, 11],\n",
              " 1: [0, 6, 7, 8, 10, 11],\n",
              " 2: [3, 4, 5, 10],\n",
              " 3: [0, 1, 9, 10, 11],\n",
              " 4: [0, 2, 4, 7],\n",
              " 5: [0, 3, 7, 8, 10, 11],\n",
              " 6: [0, 2, 3, 6, 8],\n",
              " 7: [2, 4, 9, 10, 11],\n",
              " 8: [3, 5, 6, 8],\n",
              " 9: [3, 6, 7],\n",
              " 10: [3, 4, 5, 7, 8, 9],\n",
              " 11: [6, 10, 11]}"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "heads_to_prune = dict(\n",
        "        (layer, torch.atleast_1d((1 - head_mask[layer].long()).nonzero().squeeze()).tolist()) for layer in range(len(head_mask))\n",
        "    )\n",
        "heads_to_prune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJa73YwAhBv0",
        "outputId": "00d87720-eb5d-4e41-de4b-c7db784614ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "417.6494140625"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_memory_footprint() / 1024 / 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4leSfCUFmw6f"
      },
      "outputs": [],
      "source": [
        "model.prune_heads(heads_to_prune)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwuM81Okm7CQ",
        "outputId": "05403f75-62db-404e-b46f-f78a2653d08e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "374.857666015625"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_memory_footprint() / 1024 / 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "livXsVRTwbXK",
        "outputId": "0e734f30-850b-4b87-f049-3f7416b6a05c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWxY173UnBYQ",
        "outputId": "28630226-b835-4d50-b022-8a769d089b08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "WARNING:__main__:Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "INFO:__main__:Training/evaluation parameters PruneTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "dont_normalize_global_importance=False,\n",
            "dont_normalize_importance_by_layer=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=passive,\n",
            "log_on_each_node=True,\n",
            "logging_dir=glue_bert_prune/runs/Oct25_13-58-09_217af3205d69,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "masking_amount=0.05,\n",
            "masking_threshold=0.9,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_hf,\n",
            "output_dir=glue_bert_prune,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=256,\n",
            "per_device_train_batch_size=64,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=test_32_off,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=1337,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "try_masking=True,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\n",
            "INFO:datasets.builder:Overwrite dataset info from restored data version.\n",
            "INFO:datasets.info:Loading Dataset info from /root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\n",
            "WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "INFO:datasets.info:Loading Dataset info from /root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\n",
            "100% 3/3 [00:00<00:00, 966.13it/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 488kB/s]\n",
            "[INFO|configuration_utils.py:653] 2022-10-25 13:58:16,655 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/config.json\n",
            "[INFO|configuration_utils.py:705] 2022-10-25 13:58:16,656 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"stsb\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "Downloading: 100% 29.0/29.0 [00:00<00:00, 27.6kB/s]\n",
            "[INFO|configuration_utils.py:653] 2022-10-25 13:58:18,609 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/config.json\n",
            "[INFO|configuration_utils.py:705] 2022-10-25 13:58:18,610 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "Downloading: 100% 213k/213k [00:00<00:00, 230kB/s]\n",
            "Downloading: 100% 436k/436k [00:01<00:00, 365kB/s]\n",
            "[INFO|tokenization_utils_base.py:1775] 2022-10-25 13:58:26,454 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:1775] 2022-10-25 13:58:26,454 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1775] 2022-10-25 13:58:26,455 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1775] 2022-10-25 13:58:26,455 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1775] 2022-10-25 13:58:26,455 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/tokenizer_config.json\n",
            "[INFO|configuration_utils.py:653] 2022-10-25 13:58:26,455 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/config.json\n",
            "[INFO|configuration_utils.py:705] 2022-10-25 13:58:26,456 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "Downloading: 100% 436M/436M [00:06<00:00, 66.2MB/s]\n",
            "[INFO|modeling_utils.py:2156] 2022-10-25 13:58:34,052 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/a8d257ba9925ef39f3036bfc338acf5283c512d9/pytorch_model.bin\n",
            "[WARNING|modeling_utils.py:2597] 2022-10-25 13:58:35,472 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:2609] 2022-10-25 13:58:35,472 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Running tokenizer on dataset:   0% 0/6 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-610266ccaf631a3c.arrow\n",
            "Running tokenizer on dataset:  83% 5/6 [00:00<00:00,  7.93ba/s]\n",
            "Running tokenizer on dataset:   0% 0/2 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-7dd3f99b478e68fc.arrow\n",
            "Running tokenizer on dataset:  50% 1/2 [00:00<00:00,  2.96ba/s]\n",
            "Running tokenizer on dataset:   0% 0/2 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-4b1b18db7297df46.arrow\n",
            "Running tokenizer on dataset:  50% 1/2 [00:00<00:00,  6.60ba/s]\n",
            "INFO:__main__:Sample 5060 of the training set: {'sentence1': 'Queen to name biggest ever carrier', 'sentence2': 'Queen names giant aircraft carrier', 'label': 4.199999809265137, 'idx': 5060, 'input_ids': [101, 2454, 1106, 1271, 4583, 1518, 7526, 102, 2454, 2666, 4994, 2163, 7526, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "INFO:__main__:Sample 4368 of the training set: {'sentence1': '8 arrested after deadly Bangladesh building collapse', 'sentence2': 'Four arrested as Bangladesh building toll rises to 352', 'label': 2.4000000953674316, 'idx': 4368, 'input_ids': [101, 129, 3950, 1170, 10310, 6735, 1459, 7546, 102, 3396, 3950, 1112, 6735, 1459, 10484, 9440, 1106, 2588, 1477, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "INFO:__main__:Sample 2997 of the training set: {'sentence1': \"The company didn't detail the costs of the replacement and repairs.\", 'sentence2': 'But company officials expect the costs of the replacement work to run into the millions of dollars.', 'label': 2.0, 'idx': 2997, 'input_ids': [101, 1109, 1419, 1238, 112, 189, 6505, 1103, 4692, 1104, 1103, 5627, 1105, 10528, 119, 102, 1252, 1419, 3878, 5363, 1103, 4692, 1104, 1103, 5627, 1250, 1106, 1576, 1154, 1103, 9215, 1104, 5860, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
            "[INFO|trainer.py:726] 2022-10-25 13:58:40,606 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1607] 2022-10-25 13:58:40,618 >> ***** Running training *****\n",
            "[INFO|trainer.py:1608] 2022-10-25 13:58:40,618 >>   Num examples = 5749\n",
            "[INFO|trainer.py:1609] 2022-10-25 13:58:40,618 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1610] 2022-10-25 13:58:40,618 >>   Instantaneous batch size per device = 64\n",
            "[INFO|trainer.py:1611] 2022-10-25 13:58:40,618 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "[INFO|trainer.py:1612] 2022-10-25 13:58:40,618 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1613] 2022-10-25 13:58:40,618 >>   Total optimization steps = 270\n",
            "[INFO|trainer.py:1615] 2022-10-25 13:58:40,619 >>   Number of trainable parameters = 108311041\n",
            "100% 270/270 [05:43<00:00,  1.20s/it][INFO|trainer.py:1855] 2022-10-25 14:04:24,297 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 343.6817, 'train_samples_per_second': 50.183, 'train_steps_per_second': 0.786, 'train_loss': 0.6499841195565683, 'epoch': 3.0}\n",
            "100% 270/270 [05:43<00:00,  1.27s/it]\n",
            "[INFO|trainer.py:2674] 2022-10-25 14:04:24,303 >> Saving model checkpoint to glue_bert_prune\n",
            "[INFO|configuration_utils.py:447] 2022-10-25 14:04:24,304 >> Configuration saved in glue_bert_prune/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-10-25 14:04:25,720 >> Model weights saved in glue_bert_prune/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2125] 2022-10-25 14:04:25,721 >> tokenizer config file saved in glue_bert_prune/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2132] 2022-10-25 14:04:25,721 >> Special tokens file saved in glue_bert_prune/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  train_loss               =       0.65\n",
            "  train_runtime            = 0:05:43.68\n",
            "  train_samples            =       5749\n",
            "  train_samples_per_second =     50.183\n",
            "  train_steps_per_second   =      0.786\n",
            "INFO:__main__:*** Evaluate ***\n",
            "Iteration: 100% 90/90 [01:51<00:00,  1.24s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.08687\t0.12647\t0.15700\t0.42319\t0.07445\t0.10103\t0.13112\t0.20635\t0.10404\t0.11798\t0.63355\t0.65940\n",
            "INFO:__main__:layer 2:\t0.31296\t0.36471\t0.09584\t0.44311\t0.53872\t0.10969\t0.24441\t0.12651\t0.29837\t0.24108\t0.22961\t0.35839\n",
            "INFO:__main__:layer 3:\t0.39594\t0.25143\t0.09503\t0.15382\t0.06057\t0.65738\t0.52782\t0.34176\t0.22564\t0.06243\t0.11318\t0.08138\n",
            "INFO:__main__:layer 4:\t0.01959\t0.24687\t0.08256\t0.46227\t0.13813\t0.04134\t0.18167\t0.54081\t0.49141\t0.05461\t0.29959\t0.44104\n",
            "INFO:__main__:layer 5:\t0.83598\t0.14923\t0.09976\t0.04028\t0.19065\t0.02322\t0.39650\t0.32163\t0.17312\t0.11539\t0.12880\t0.27632\n",
            "INFO:__main__:layer 6:\t0.28722\t0.20369\t0.12045\t0.28182\t0.08110\t0.33953\t0.19919\t0.22024\t0.12024\t0.52595\t0.16888\t0.63421\n",
            "INFO:__main__:layer 7:\t0.95686\t0.08771\t0.03335\t0.14002\t0.15498\t0.12711\t0.03750\t0.09191\t0.04191\t0.20017\t0.21886\t0.31024\n",
            "INFO:__main__:layer 8:\t0.16866\t0.53174\t0.34762\t0.52755\t0.29147\t0.27308\t0.21519\t0.36197\t0.19016\t0.17240\t0.17573\t0.03866\n",
            "INFO:__main__:layer 9:\t0.02193\t0.08722\t1.00000\t0.09864\t0.02967\t0.23978\t0.06203\t0.10515\t0.04917\t0.09344\t0.21060\t0.20284\n",
            "INFO:__main__:layer 10:\t0.06682\t0.66826\t0.34747\t0.03897\t0.02728\t0.08342\t0.09307\t0.03685\t0.09775\t0.37024\t0.62046\t0.21693\n",
            "INFO:__main__:layer 11:\t0.40541\t0.12440\t0.14467\t0.00000\t0.05077\t0.03039\t0.05068\t0.75175\t0.22636\t0.09327\t0.50263\t0.29152\n",
            "INFO:__main__:layer 12:\t0.07455\t0.24131\t0.11064\t0.26519\t0.06630\t0.55950\t0.30285\t0.48792\t0.47791\t0.25413\t0.24786\t0.05692\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t112\t89\t78\t24\t118\t100\t85\t65\t99\t93\t8\t5\n",
            "INFO:__main__:layer 2:\t37\t29\t104\t22\t12\t97\t53\t88\t41\t55\t57\t31\n",
            "INFO:__main__:layer 3:\t27\t50\t105\t80\t123\t6\t14\t34\t59\t121\t95\t115\n",
            "INFO:__main__:layer 4:\t142\t52\t114\t21\t84\t130\t72\t11\t18\t125\t40\t23\n",
            "INFO:__main__:layer 5:\t2\t81\t101\t131\t70\t140\t26\t36\t74\t94\t86\t46\n",
            "INFO:__main__:layer 6:\t44\t66\t91\t45\t116\t35\t69\t60\t92\t16\t76\t7\n",
            "INFO:__main__:layer 7:\t1\t110\t136\t83\t79\t87\t134\t109\t129\t68\t61\t38\n",
            "INFO:__main__:layer 8:\t77\t13\t32\t15\t43\t47\t63\t30\t71\t75\t73\t133\n",
            "INFO:__main__:layer 9:\t141\t111\t0\t102\t138\t56\t122\t98\t128\t106\t64\t67\n",
            "INFO:__main__:layer 10:\t119\t4\t33\t132\t139\t113\t108\t135\t103\t28\t9\t62\n",
            "INFO:__main__:layer 11:\t25\t90\t82\t143\t126\t137\t127\t3\t58\t107\t17\t42\n",
            "INFO:__main__:layer 12:\t117\t54\t96\t48\t120\t10\t39\t19\t20\t49\t51\t124\n",
            "INFO:__main__:Pruning: original score: 0.952192, threshold: 0.856973\n",
            "INFO:__main__:Heads to mask: [123, 36, 96, 53, 112, 100, 125]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 12:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "Iteration: 100% 90/90 [01:51<00:00,  1.24s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.09250\t0.28929\t0.31809\t0.17556\t0.11985\t0.12758\t0.19324\t0.54283\t0.25989\t0.41073\t0.61620\t0.53549\n",
            "INFO:__main__:layer 2:\t0.36990\t0.17475\t0.13516\t0.08738\t0.37364\t0.14874\t0.61714\t0.24275\t0.11318\t0.34858\t0.69189\t0.29133\n",
            "INFO:__main__:layer 3:\t0.40468\t0.14609\t0.26373\t0.31941\t0.04988\t0.78815\t0.46289\t0.16990\t0.40385\t0.27643\t0.09555\t0.15098\n",
            "INFO:__main__:layer 4:\t0.57845\t0.23708\t0.06862\t0.42776\t0.13238\t0.10427\t0.12652\t0.81574\t0.23690\t0.05430\t0.05463\t0.39400\n",
            "INFO:__main__:layer 5:\t0.53338\t0.26413\t0.06865\t0.09561\t0.12693\t0.25347\t0.12474\t0.23021\t0.08707\t0.04964\t0.13091\t0.98559\n",
            "INFO:__main__:layer 6:\t0.27280\t0.16979\t0.17419\t0.17526\t0.21664\t0.21276\t0.42058\t0.06735\t0.49865\t0.71773\t0.09263\t0.53284\n",
            "INFO:__main__:layer 7:\t0.74983\t0.28318\t0.02846\t0.31902\t0.35031\t0.17093\t0.36458\t0.24610\t0.18169\t0.24993\t0.18878\t0.51874\n",
            "INFO:__main__:layer 8:\t0.27481\t0.53247\t0.07131\t0.06868\t0.42625\t0.30444\t0.53731\t0.27460\t0.60581\t0.11370\t0.10787\t0.30465\n",
            "INFO:__main__:layer 9:\t0.99243\t0.11160\t0.24247\t0.26850\t0.07299\t0.16204\t0.00681\t0.11895\t0.18952\t0.10263\t0.05829\t0.54277\n",
            "INFO:__main__:layer 10:\t0.08485\t0.80931\t0.19493\t0.07749\t0.17364\t0.08468\t0.13104\t0.32684\t0.12650\t0.58021\t0.49597\t0.19425\n",
            "INFO:__main__:layer 11:\t0.27211\t0.17884\t0.17360\t0.00000\t0.02573\t0.04137\t0.08888\t1.00000\t0.23677\t0.05861\t0.21702\t0.51725\n",
            "INFO:__main__:layer 12:\t0.05786\t0.18181\t0.07919\t0.24940\t0.12469\t0.20399\t0.29067\t0.77140\t0.71640\t0.20476\t0.19458\t0.25951\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t118\t48\t43\t84\t107\t101\t78\t16\t58\t31\t12\t19\n",
            "INFO:__main__:layer 2:\t36\t86\t97\t120\t35\t95\t11\t64\t110\t39\t10\t46\n",
            "INFO:__main__:layer 3:\t32\t96\t57\t41\t137\t5\t27\t91\t33\t50\t116\t94\n",
            "INFO:__main__:layer 4:\t15\t66\t130\t28\t98\t113\t103\t3\t67\t136\t135\t34\n",
            "INFO:__main__:layer 5:\t20\t56\t129\t115\t102\t60\t105\t69\t121\t138\t100\t2\n",
            "INFO:__main__:layer 6:\t53\t92\t87\t85\t71\t72\t30\t131\t25\t8\t117\t21\n",
            "INFO:__main__:layer 7:\t7\t49\t140\t42\t38\t90\t37\t63\t82\t61\t80\t23\n",
            "INFO:__main__:layer 8:\t51\t22\t127\t128\t29\t45\t18\t52\t13\t109\t112\t44\n",
            "INFO:__main__:layer 9:\t1\t111\t65\t55\t126\t93\t142\t108\t79\t114\t133\t17\n",
            "INFO:__main__:layer 10:\t122\t4\t75\t125\t88\t123\t99\t40\t104\t14\t26\t77\n",
            "INFO:__main__:layer 11:\t54\t83\t89\t143\t141\t139\t119\t0\t68\t132\t70\t24\n",
            "INFO:__main__:layer 12:\t134\t81\t124\t62\t106\t74\t47\t6\t9\t73\t76\t59\n",
            "INFO:__main__:Masking: current score: 0.950859, remaining heads 137 (95.1 percents)\n",
            "INFO:__main__:Heads to mask: [102, 124, 74, 57, 28, 45, 46]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 12:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "Iteration: 100% 90/90 [01:51<00:00,  1.24s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.45066\t0.16277\t0.08198\t0.23191\t0.44007\t0.27453\t0.23635\t0.21808\t0.10195\t0.30616\t0.41522\t0.77884\n",
            "INFO:__main__:layer 2:\t0.16205\t0.20398\t0.10494\t0.62594\t0.25923\t0.13696\t0.24940\t0.36047\t0.26936\t0.15496\t0.37561\t0.74905\n",
            "INFO:__main__:layer 3:\t0.26453\t0.05459\t0.14861\t0.93300\t0.39152\t0.29253\t0.12553\t0.32147\t0.45041\t0.06298\t0.16491\t0.06780\n",
            "INFO:__main__:layer 4:\t0.46155\t0.10396\t0.01803\t0.16438\t0.23612\t0.09823\t0.11880\t0.40367\t0.47526\t0.75890\t0.48359\t0.15785\n",
            "INFO:__main__:layer 5:\t0.38716\t0.17109\t0.04849\t0.20427\t0.07956\t0.36523\t0.05927\t0.15229\t0.05549\t1.00000\t0.37407\t0.19193\n",
            "INFO:__main__:layer 6:\t0.80285\t0.20104\t0.50789\t0.06457\t0.05456\t0.28323\t0.47582\t0.10733\t0.18176\t0.40276\t0.06705\t0.29602\n",
            "INFO:__main__:layer 7:\t0.65524\t0.18904\t0.04724\t0.33845\t0.75897\t0.23525\t0.06702\t0.33449\t0.24809\t0.22011\t0.06821\t0.33085\n",
            "INFO:__main__:layer 8:\t0.12504\t0.43828\t0.10674\t0.26963\t0.12745\t0.51436\t0.69315\t0.16432\t0.57006\t0.01722\t0.25791\t0.28112\n",
            "INFO:__main__:layer 9:\t0.89147\t0.03146\t0.70182\t0.17108\t0.03993\t0.11893\t0.12566\t0.17492\t0.11646\t0.05675\t0.04536\t0.42253\n",
            "INFO:__main__:layer 10:\t0.27865\t0.61203\t0.52458\t0.04082\t0.22569\t0.08316\t0.10302\t0.43103\t0.08276\t0.40847\t0.61694\t0.12127\n",
            "INFO:__main__:layer 11:\t0.31951\t0.20953\t0.09687\t0.00000\t0.23342\t0.06585\t0.08109\t0.88722\t0.29293\t0.01020\t0.44240\t0.52627\n",
            "INFO:__main__:layer 12:\t0.25051\t0.52772\t0.21818\t0.21517\t0.34993\t0.61849\t0.37802\t0.30580\t0.54056\t0.14828\t0.14335\t0.16719\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t27\t92\t119\t72\t30\t59\t68\t76\t114\t51\t34\t5\n",
            "INFO:__main__:layer 2:\t93\t80\t111\t12\t63\t100\t66\t44\t61\t95\t41\t8\n",
            "INFO:__main__:layer 3:\t62\t132\t97\t1\t38\t55\t103\t49\t28\t128\t89\t123\n",
            "INFO:__main__:layer 4:\t26\t112\t140\t90\t69\t115\t107\t36\t25\t7\t23\t94\n",
            "INFO:__main__:layer 5:\t39\t86\t134\t79\t121\t43\t129\t96\t131\t0\t42\t82\n",
            "INFO:__main__:layer 6:\t4\t81\t22\t127\t133\t56\t24\t109\t84\t37\t124\t53\n",
            "INFO:__main__:layer 7:\t11\t83\t135\t46\t6\t70\t125\t47\t67\t74\t122\t48\n",
            "INFO:__main__:layer 8:\t104\t31\t110\t60\t101\t21\t10\t91\t16\t141\t64\t57\n",
            "INFO:__main__:layer 9:\t2\t139\t9\t87\t138\t106\t102\t85\t108\t130\t136\t33\n",
            "INFO:__main__:layer 10:\t58\t15\t20\t137\t73\t117\t113\t32\t118\t35\t14\t105\n",
            "INFO:__main__:layer 11:\t50\t78\t116\t143\t71\t126\t120\t3\t54\t142\t29\t19\n",
            "INFO:__main__:layer 12:\t65\t18\t75\t77\t45\t13\t40\t52\t17\t98\t99\t88\n",
            "INFO:__main__:Masking: current score: 0.949798, remaining heads 130 (90.3 percents)\n",
            "INFO:__main__:Heads to mask: [129, 93, 38, 97, 111, 106, 50]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 12:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "Iteration: 100% 90/90 [01:51<00:00,  1.24s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.64463\t0.15473\t0.20548\t0.17851\t0.17661\t0.20442\t0.36634\t0.50870\t0.30007\t0.21666\t0.52444\t0.34821\n",
            "INFO:__main__:layer 2:\t0.13170\t0.35407\t0.09774\t0.41519\t0.30997\t0.28532\t0.17985\t0.37962\t0.42722\t0.10917\t0.48589\t0.63548\n",
            "INFO:__main__:layer 3:\t0.41644\t0.10738\t0.07834\t0.47905\t0.89327\t0.35940\t0.13157\t0.26926\t0.13195\t0.07435\t0.17578\t0.15907\n",
            "INFO:__main__:layer 4:\t0.41400\t0.04393\t0.33083\t0.30507\t0.31881\t0.15258\t0.07993\t0.27433\t0.38578\t0.58829\t0.63960\t0.16522\n",
            "INFO:__main__:layer 5:\t0.53263\t0.31494\t0.38434\t0.25702\t0.19440\t0.35940\t0.04556\t0.26502\t0.07041\t0.71610\t0.30524\t0.25849\n",
            "INFO:__main__:layer 6:\t0.82649\t0.19517\t0.12390\t0.04864\t0.05998\t0.47324\t0.57289\t0.14936\t0.03773\t0.33817\t0.11299\t0.26756\n",
            "INFO:__main__:layer 7:\t0.89250\t0.22648\t0.08932\t0.40838\t0.45593\t0.38962\t0.09655\t0.19730\t0.15934\t0.11457\t0.02725\t0.21648\n",
            "INFO:__main__:layer 8:\t0.09664\t0.36194\t0.07970\t0.33357\t0.28049\t0.62479\t0.68417\t0.23332\t0.47658\t0.04283\t0.09050\t0.16906\n",
            "INFO:__main__:layer 9:\t0.79492\t0.06811\t0.79088\t0.13706\t0.06762\t0.07509\t0.11665\t0.22224\t0.04183\t0.08309\t0.27833\t0.28050\n",
            "INFO:__main__:layer 10:\t0.34420\t0.25681\t0.10480\t0.19647\t0.11549\t0.09572\t0.08113\t0.35806\t0.08115\t0.24289\t1.00000\t0.24655\n",
            "INFO:__main__:layer 11:\t0.62097\t0.33029\t0.09093\t0.00000\t0.13549\t0.03549\t0.07426\t0.85466\t0.08141\t0.07797\t0.10428\t0.48696\n",
            "INFO:__main__:layer 12:\t0.19077\t0.30407\t0.17241\t0.33541\t0.10335\t0.59182\t0.35659\t0.15314\t0.81737\t0.13056\t0.10079\t0.19366\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t10\t92\t75\t84\t85\t76\t36\t20\t56\t73\t19\t43\n",
            "INFO:__main__:layer 2:\t99\t42\t113\t29\t52\t57\t83\t35\t27\t107\t22\t12\n",
            "INFO:__main__:layer 3:\t28\t108\t126\t23\t1\t39\t100\t62\t98\t129\t86\t91\n",
            "INFO:__main__:layer 4:\t30\t137\t48\t54\t50\t94\t124\t61\t33\t16\t11\t89\n",
            "INFO:__main__:layer 5:\t18\t51\t34\t66\t80\t38\t136\t64\t131\t8\t53\t65\n",
            "INFO:__main__:layer 6:\t4\t79\t102\t135\t134\t25\t17\t95\t140\t45\t106\t63\n",
            "INFO:__main__:layer 7:\t2\t71\t119\t31\t26\t32\t115\t77\t90\t105\t142\t74\n",
            "INFO:__main__:layer 8:\t114\t37\t125\t47\t59\t13\t9\t70\t24\t138\t118\t88\n",
            "INFO:__main__:layer 9:\t6\t132\t7\t96\t133\t128\t103\t72\t139\t120\t60\t58\n",
            "INFO:__main__:layer 10:\t44\t67\t109\t78\t104\t116\t123\t40\t122\t69\t0\t68\n",
            "INFO:__main__:layer 11:\t14\t49\t117\t143\t97\t141\t130\t3\t121\t127\t110\t21\n",
            "INFO:__main__:layer 12:\t82\t55\t87\t46\t111\t15\t41\t93\t5\t101\t112\t81\n",
            "INFO:__main__:Masking: current score: 0.948556, remaining heads 123 (85.4 percents)\n",
            "INFO:__main__:Heads to mask: [82, 68, 104, 37, 54, 63, 64]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 12:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "Iteration: 100% 90/90 [01:51<00:00,  1.24s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.14322\t0.25611\t0.49181\t0.16285\t0.06267\t0.19983\t0.21985\t0.20899\t0.08631\t0.53264\t0.27117\t0.58011\n",
            "INFO:__main__:layer 2:\t0.32359\t0.10009\t0.12749\t0.19425\t0.40458\t0.23232\t0.36201\t0.31827\t0.08294\t0.49038\t0.51658\t0.23337\n",
            "INFO:__main__:layer 3:\t0.17100\t0.25233\t0.03734\t0.30316\t0.50514\t0.44597\t0.28962\t0.14233\t0.29431\t0.16247\t0.23016\t0.52689\n",
            "INFO:__main__:layer 4:\t0.21491\t0.72413\t0.22764\t0.40639\t0.12509\t0.01000\t0.06489\t0.28421\t0.17995\t0.39924\t0.33784\t0.04730\n",
            "INFO:__main__:layer 5:\t0.16415\t0.06275\t0.24107\t0.08977\t0.02768\t0.23901\t0.83329\t0.25955\t0.02605\t0.47857\t0.17104\t0.16514\n",
            "INFO:__main__:layer 6:\t0.36138\t0.01325\t0.05819\t0.16608\t0.27311\t0.21641\t0.40583\t0.01076\t0.23474\t0.35369\t0.00000\t0.75662\n",
            "INFO:__main__:layer 7:\t1.00000\t0.01471\t0.00519\t0.11682\t0.04316\t0.08913\t0.06727\t0.11950\t0.08713\t0.00534\t0.10137\t0.40009\n",
            "INFO:__main__:layer 8:\t0.01705\t0.14942\t0.10096\t0.20542\t0.14653\t0.99890\t0.28768\t0.10294\t0.14434\t0.02132\t0.03680\t0.06730\n",
            "INFO:__main__:layer 9:\t0.54769\t0.15966\t0.28358\t0.10376\t0.12215\t0.08369\t0.15442\t0.08362\t0.71179\t0.08509\t0.14240\t0.44200\n",
            "INFO:__main__:layer 10:\t0.07391\t0.94065\t0.25000\t0.10427\t0.19625\t0.02702\t0.03921\t0.16688\t0.17701\t0.35015\t0.13042\t0.07324\n",
            "INFO:__main__:layer 11:\t0.34030\t0.24849\t0.05613\t0.00315\t0.03959\t0.07862\t0.00988\t0.63841\t0.19767\t0.12433\t0.23497\t0.70642\n",
            "INFO:__main__:layer 12:\t0.10971\t0.10917\t0.06085\t0.04916\t0.08763\t0.26491\t0.31847\t0.31322\t0.91258\t0.08681\t0.22738\t0.08248\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t83\t46\t16\t76\t119\t64\t59\t62\t106\t12\t43\t10\n",
            "INFO:__main__:layer 2:\t32\t100\t87\t67\t23\t55\t26\t34\t110\t17\t14\t54\n",
            "INFO:__main__:layer 3:\t71\t47\t128\t36\t15\t19\t38\t85\t37\t77\t56\t13\n",
            "INFO:__main__:layer 4:\t61\t6\t57\t21\t88\t138\t117\t40\t68\t25\t31\t124\n",
            "INFO:__main__:layer 5:\t75\t118\t50\t101\t130\t51\t4\t45\t132\t18\t70\t74\n",
            "INFO:__main__:layer 6:\t27\t136\t121\t73\t42\t60\t22\t137\t53\t28\t143\t5\n",
            "INFO:__main__:layer 7:\t0\t135\t141\t92\t125\t102\t116\t91\t104\t140\t98\t24\n",
            "INFO:__main__:layer 8:\t134\t80\t99\t63\t81\t1\t39\t97\t82\t133\t129\t115\n",
            "INFO:__main__:layer 9:\t11\t78\t41\t96\t90\t108\t79\t109\t7\t107\t84\t20\n",
            "INFO:__main__:layer 10:\t113\t2\t48\t95\t66\t131\t127\t72\t69\t29\t86\t114\n",
            "INFO:__main__:layer 11:\t30\t49\t122\t142\t126\t112\t139\t9\t65\t89\t52\t8\n",
            "INFO:__main__:layer 12:\t93\t94\t120\t123\t103\t44\t33\t35\t3\t105\t58\t111\n",
            "INFO:__main__:Masking: current score: 0.946259, remaining heads 116 (80.6 percents)\n",
            "INFO:__main__:Heads to mask: [70, 81, 126, 41, 67, 61, 73]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 12:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "Iteration: 100% 90/90 [01:51<00:00,  1.24s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.11625\t0.26382\t0.45359\t0.22758\t0.09642\t0.24935\t0.32411\t0.38588\t0.13902\t0.56483\t0.43721\t0.61361\n",
            "INFO:__main__:layer 2:\t0.34575\t0.11419\t0.06750\t0.45511\t0.11712\t0.29573\t0.58627\t0.13037\t0.06839\t0.47385\t0.47181\t0.56407\n",
            "INFO:__main__:layer 3:\t0.54587\t0.37533\t0.11408\t0.37670\t0.48732\t0.64736\t0.30727\t0.04953\t0.16990\t0.12955\t0.12903\t0.40690\n",
            "INFO:__main__:layer 4:\t0.23551\t0.74279\t0.24783\t0.34388\t0.15261\t0.16202\t0.01565\t0.44317\t0.23018\t0.52173\t0.45294\t0.11540\n",
            "INFO:__main__:layer 5:\t0.15252\t0.05221\t0.52254\t0.15894\t0.06171\t0.42350\t0.72094\t0.35200\t0.02121\t0.62699\t0.08095\t0.17994\n",
            "INFO:__main__:layer 6:\t0.17903\t0.43603\t0.14219\t0.24472\t0.39251\t0.11922\t0.50420\t0.38509\t0.40417\t0.35156\t0.22663\t0.59853\n",
            "INFO:__main__:layer 7:\t0.63810\t0.47921\t0.08804\t0.23795\t0.18165\t0.29820\t0.14459\t0.27212\t0.14572\t0.60836\t0.24315\t0.45319\n",
            "INFO:__main__:layer 8:\t0.18069\t0.07602\t0.07923\t0.22331\t0.26741\t1.00000\t0.43920\t0.17834\t0.32641\t0.06493\t0.10868\t0.27080\n",
            "INFO:__main__:layer 9:\t0.98918\t0.10116\t0.32753\t0.18766\t0.12646\t0.08650\t0.13647\t0.05046\t0.54864\t0.12942\t0.11517\t0.28755\n",
            "INFO:__main__:layer 10:\t0.16820\t0.88444\t0.34195\t0.15422\t0.31029\t0.06388\t0.04054\t0.33432\t0.25272\t0.36571\t0.44765\t0.13202\n",
            "INFO:__main__:layer 11:\t0.59397\t0.27671\t0.09157\t0.00000\t0.09676\t0.07701\t0.05566\t0.77461\t0.13801\t0.08936\t0.28628\t0.65070\n",
            "INFO:__main__:layer 12:\t0.16096\t0.06556\t0.21610\t0.11225\t0.15401\t0.44719\t0.34284\t0.34029\t0.98418\t0.10575\t0.20193\t0.13577\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t111\t67\t28\t76\t121\t69\t56\t41\t99\t16\t35\t11\n",
            "INFO:__main__:layer 2:\t48\t114\t131\t27\t110\t60\t15\t104\t130\t25\t26\t17\n",
            "INFO:__main__:layer 3:\t19\t44\t115\t43\t23\t8\t58\t139\t87\t105\t107\t38\n",
            "INFO:__main__:layer 4:\t74\t5\t70\t49\t94\t89\t142\t33\t75\t21\t30\t112\n",
            "INFO:__main__:layer 5:\t95\t137\t20\t91\t135\t37\t6\t46\t141\t10\t126\t84\n",
            "INFO:__main__:layer 6:\t85\t36\t98\t71\t40\t109\t22\t42\t39\t47\t77\t13\n",
            "INFO:__main__:layer 7:\t9\t24\t124\t73\t82\t59\t97\t64\t96\t12\t72\t29\n",
            "INFO:__main__:layer 8:\t83\t129\t127\t78\t66\t0\t34\t86\t55\t133\t117\t65\n",
            "INFO:__main__:layer 9:\t1\t119\t54\t81\t108\t125\t101\t138\t18\t106\t113\t61\n",
            "INFO:__main__:layer 10:\t88\t3\t51\t92\t57\t134\t140\t53\t68\t45\t31\t103\n",
            "INFO:__main__:layer 11:\t14\t63\t122\t143\t120\t128\t136\t4\t100\t123\t62\t7\n",
            "INFO:__main__:layer 12:\t90\t132\t79\t116\t93\t32\t50\t52\t2\t118\t80\t102\n",
            "INFO:__main__:Masking: current score: 0.942663, remaining heads 109 (75.7 percents)\n",
            "INFO:__main__:Heads to mask: [42, 56, 114, 31, 103, 49, 52]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 12:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "Iteration: 100% 90/90 [01:51<00:00,  1.24s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.38831\t0.16457\t0.35133\t0.12562\t0.11350\t0.29584\t0.12508\t0.35222\t0.20779\t0.55660\t0.27869\t0.36738\n",
            "INFO:__main__:layer 2:\t0.50176\t0.15445\t0.10289\t0.51596\t0.19364\t0.38917\t0.18473\t0.12079\t0.33023\t0.32152\t0.18641\t0.29287\n",
            "INFO:__main__:layer 3:\t0.16811\t0.21981\t0.15478\t0.41034\t0.46540\t0.22837\t0.13810\t0.62676\t0.10190\t0.02574\t0.20229\t0.35044\n",
            "INFO:__main__:layer 4:\t0.30615\t0.37032\t0.32730\t0.20552\t0.17314\t0.20123\t0.39619\t0.23017\t0.08939\t0.43179\t0.46662\t0.22223\n",
            "INFO:__main__:layer 5:\t0.13038\t0.34330\t0.34307\t0.15962\t0.44946\t0.23053\t0.39371\t0.26105\t0.12899\t0.43005\t0.28537\t0.28754\n",
            "INFO:__main__:layer 6:\t0.09825\t0.29428\t0.17634\t0.17394\t0.29798\t0.23693\t0.48866\t0.29455\t0.36163\t0.19320\t0.15987\t0.54870\n",
            "INFO:__main__:layer 7:\t0.78403\t0.28716\t0.05950\t0.17686\t0.13303\t0.30256\t0.13582\t0.15271\t0.12973\t0.39782\t0.13180\t0.22369\n",
            "INFO:__main__:layer 8:\t0.06913\t0.04792\t0.05619\t0.10032\t0.06152\t1.00000\t0.19039\t0.04487\t0.22186\t0.01389\t0.05447\t0.12951\n",
            "INFO:__main__:layer 9:\t0.57433\t0.06621\t0.63349\t0.14218\t0.06146\t0.17303\t0.10882\t0.14906\t0.41526\t0.03343\t0.11530\t0.34023\n",
            "INFO:__main__:layer 10:\t0.25751\t0.50313\t0.26666\t0.17662\t0.17635\t0.03078\t0.08107\t0.21685\t0.19850\t0.39003\t0.65058\t0.05255\n",
            "INFO:__main__:layer 11:\t0.47198\t0.31298\t0.07939\t0.00000\t0.07614\t0.05815\t0.05988\t0.60551\t0.12669\t0.08804\t0.18101\t0.60343\n",
            "INFO:__main__:layer 12:\t0.13921\t0.04734\t0.09416\t0.09770\t0.06669\t0.35083\t0.37285\t0.33482\t0.80367\t0.05709\t0.20150\t0.13581\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t28\t88\t34\t107\t111\t48\t108\t33\t68\t9\t55\t31\n",
            "INFO:__main__:layer 2:\t13\t92\t113\t11\t74\t27\t78\t109\t41\t43\t77\t51\n",
            "INFO:__main__:layer 3:\t87\t66\t91\t22\t17\t62\t97\t5\t114\t141\t70\t36\n",
            "INFO:__main__:layer 4:\t45\t30\t42\t69\t85\t72\t24\t61\t119\t19\t16\t64\n",
            "INFO:__main__:layer 5:\t102\t37\t38\t90\t18\t60\t25\t57\t105\t20\t54\t52\n",
            "INFO:__main__:layer 6:\t116\t50\t83\t84\t47\t59\t14\t49\t32\t75\t89\t10\n",
            "INFO:__main__:layer 7:\t2\t53\t130\t80\t100\t46\t98\t93\t103\t23\t101\t63\n",
            "INFO:__main__:layer 8:\t124\t136\t133\t115\t127\t0\t76\t138\t65\t142\t134\t104\n",
            "INFO:__main__:layer 9:\t8\t126\t4\t95\t128\t86\t112\t94\t21\t139\t110\t39\n",
            "INFO:__main__:layer 10:\t58\t12\t56\t81\t82\t140\t121\t67\t73\t26\t3\t135\n",
            "INFO:__main__:layer 11:\t15\t44\t122\t143\t123\t131\t129\t6\t106\t120\t79\t7\n",
            "INFO:__main__:layer 12:\t96\t137\t118\t117\t125\t35\t29\t40\t1\t132\t71\t99\n",
            "INFO:__main__:Masking: current score: 0.940533, remaining heads 102 (70.8 percents)\n",
            "INFO:__main__:Heads to mask: [33, 113, 105, 91, 133, 85, 119]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 12:\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "Iteration: 100% 90/90 [01:51<00:00,  1.24s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.07270\t0.11548\t0.04960\t0.09472\t0.13881\t0.38236\t0.51425\t0.70897\t0.14351\t0.30728\t0.10150\t0.68505\n",
            "INFO:__main__:layer 2:\t0.45876\t0.32240\t0.25743\t0.31467\t0.19580\t0.29638\t0.58483\t0.14350\t0.41530\t0.16515\t0.17914\t0.59348\n",
            "INFO:__main__:layer 3:\t0.23938\t0.28853\t0.15117\t0.26190\t0.58870\t0.23632\t0.05115\t0.73759\t0.17717\t0.41060\t0.28270\t0.30511\n",
            "INFO:__main__:layer 4:\t0.32882\t0.33546\t0.36690\t0.13077\t0.23542\t0.22906\t0.48461\t0.13508\t0.35538\t0.43033\t0.62531\t0.34083\n",
            "INFO:__main__:layer 5:\t0.19372\t0.35845\t0.39689\t0.25674\t0.58190\t0.26959\t0.25310\t0.22580\t0.10828\t0.49183\t0.35356\t0.50756\n",
            "INFO:__main__:layer 6:\t0.40392\t0.34485\t0.23958\t0.21071\t0.32588\t0.21283\t0.54112\t0.38084\t0.44330\t0.10717\t0.19574\t0.57673\n",
            "INFO:__main__:layer 7:\t0.49616\t0.49676\t0.07901\t0.22333\t0.36938\t0.33620\t0.19834\t0.41453\t0.13207\t0.46859\t0.32714\t0.44537\n",
            "INFO:__main__:layer 8:\t0.10375\t0.57688\t0.04300\t0.16486\t0.17954\t0.77917\t0.43742\t0.51369\t0.27190\t0.04020\t0.07003\t0.09957\n",
            "INFO:__main__:layer 9:\t0.52753\t0.04615\t1.00000\t0.14633\t0.05178\t0.04848\t0.11010\t0.05605\t0.35926\t0.10078\t0.25270\t0.18782\n",
            "INFO:__main__:layer 10:\t0.33208\t0.69120\t0.19312\t0.10277\t0.08540\t0.11412\t0.01931\t0.12928\t0.06882\t0.06374\t0.93714\t0.03238\n",
            "INFO:__main__:layer 11:\t0.74464\t0.27254\t0.02890\t0.00000\t0.06177\t0.06551\t0.07068\t0.72874\t0.10208\t0.04460\t0.10645\t0.60285\n",
            "INFO:__main__:layer 12:\t0.16099\t0.46493\t0.15531\t0.23502\t0.03915\t0.52000\t0.32753\t0.05011\t0.90236\t0.12101\t0.10545\t0.12206\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t122\t106\t133\t119\t99\t40\t21\t7\t97\t59\t116\t9\n",
            "INFO:__main__:layer 2:\t30\t57\t68\t58\t83\t61\t14\t98\t35\t91\t89\t12\n",
            "INFO:__main__:layer 3:\t73\t62\t95\t67\t13\t74\t131\t5\t90\t37\t63\t60\n",
            "INFO:__main__:layer 4:\t53\t51\t43\t102\t75\t77\t27\t100\t46\t34\t10\t49\n",
            "INFO:__main__:layer 5:\t85\t45\t39\t69\t15\t66\t70\t78\t109\t26\t47\t23\n",
            "INFO:__main__:layer 6:\t38\t48\t72\t81\t56\t80\t18\t41\t32\t110\t84\t17\n",
            "INFO:__main__:layer 7:\t25\t24\t121\t79\t42\t50\t82\t36\t101\t28\t55\t31\n",
            "INFO:__main__:layer 8:\t113\t16\t137\t92\t88\t3\t33\t22\t65\t138\t124\t118\n",
            "INFO:__main__:layer 9:\t19\t135\t0\t96\t130\t134\t108\t129\t44\t117\t71\t87\n",
            "INFO:__main__:layer 10:\t52\t8\t86\t114\t120\t107\t142\t103\t125\t127\t1\t140\n",
            "INFO:__main__:layer 11:\t4\t64\t141\t143\t128\t126\t123\t6\t115\t136\t111\t11\n",
            "INFO:__main__:layer 12:\t93\t29\t94\t76\t139\t20\t54\t132\t2\t105\t112\t104\n",
            "INFO:__main__:Masking: current score: 0.937716, remaining heads 95 (66.0 percents)\n",
            "INFO:__main__:Heads to mask: [122, 136, 86, 101, 2, 139, 30]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 12:\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "Iteration: 100% 90/90 [01:51<00:00,  1.24s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.23755\t0.23161\t0.36492\t0.05074\t0.06183\t0.08270\t0.16359\t0.65227\t0.12223\t0.25475\t0.57811\t0.45520\n",
            "INFO:__main__:layer 2:\t0.46062\t0.17703\t0.11384\t0.07718\t0.46689\t0.08964\t0.63366\t0.13830\t0.16546\t0.15676\t0.58744\t0.15690\n",
            "INFO:__main__:layer 3:\t0.14955\t0.06466\t0.40916\t0.16995\t0.18335\t0.18396\t0.95211\t0.15528\t0.32588\t0.09337\t0.02746\t0.07256\n",
            "INFO:__main__:layer 4:\t0.24997\t0.43390\t0.20863\t0.63555\t0.07920\t0.19935\t0.16497\t0.55405\t0.17478\t0.30605\t0.32511\t0.12820\n",
            "INFO:__main__:layer 5:\t0.10111\t0.45971\t0.30932\t0.03531\t0.30305\t0.26617\t0.61884\t0.32954\t0.15523\t0.48961\t0.16671\t0.24480\n",
            "INFO:__main__:layer 6:\t0.39275\t0.28580\t0.03737\t0.11458\t0.27040\t0.18352\t0.33552\t0.18499\t0.20563\t0.59795\t0.11087\t0.64119\n",
            "INFO:__main__:layer 7:\t1.00000\t0.26090\t0.06911\t0.13375\t0.05313\t0.16706\t0.00000\t0.04492\t0.06952\t0.40329\t0.08672\t0.22438\n",
            "INFO:__main__:layer 8:\t0.14791\t0.46426\t0.38086\t0.15039\t0.31272\t0.83084\t0.30272\t0.11246\t0.11450\t0.05020\t0.04039\t0.14299\n",
            "INFO:__main__:layer 9:\t0.70022\t0.21570\t0.28433\t0.07467\t0.16120\t0.31467\t0.10071\t0.57915\t0.12299\t0.33701\t0.02010\t0.32781\n",
            "INFO:__main__:layer 10:\t0.16368\t0.37869\t0.21230\t0.05649\t0.11150\t0.10306\t0.08562\t0.34281\t0.28382\t0.72839\t0.32083\t0.49878\n",
            "INFO:__main__:layer 11:\t0.65593\t0.01430\t0.19220\t0.01612\t0.01548\t0.04008\t0.04672\t0.14320\t0.23544\t0.14353\t0.86124\t0.19417\n",
            "INFO:__main__:layer 12:\t0.04629\t0.10106\t0.11380\t0.10151\t0.29798\t0.05251\t0.25293\t0.85371\t0.46577\t0.32916\t0.30180\t0.03632\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t60\t62\t32\t128\t124\t116\t83\t8\t99\t56\t16\t25\n",
            "INFO:__main__:layer 2:\t23\t75\t102\t118\t20\t113\t11\t95\t80\t86\t14\t85\n",
            "INFO:__main__:layer 3:\t90\t123\t27\t77\t74\t72\t1\t87\t39\t112\t138\t120\n",
            "INFO:__main__:layer 4:\t58\t26\t66\t10\t117\t68\t81\t17\t76\t45\t40\t97\n",
            "INFO:__main__:layer 5:\t109\t24\t44\t137\t46\t54\t12\t36\t88\t19\t79\t59\n",
            "INFO:__main__:layer 6:\t29\t50\t135\t100\t53\t73\t35\t71\t67\t13\t106\t9\n",
            "INFO:__main__:layer 7:\t0\t55\t122\t96\t126\t78\t143\t132\t121\t28\t114\t63\n",
            "INFO:__main__:layer 8:\t91\t22\t30\t89\t43\t4\t47\t104\t101\t129\t133\t94\n",
            "INFO:__main__:layer 9:\t6\t64\t51\t119\t84\t42\t111\t15\t98\t34\t139\t38\n",
            "INFO:__main__:layer 10:\t82\t31\t65\t125\t105\t107\t115\t33\t52\t5\t41\t18\n",
            "INFO:__main__:layer 11:\t7\t142\t70\t140\t141\t134\t130\t93\t61\t92\t2\t69\n",
            "INFO:__main__:layer 12:\t131\t110\t103\t108\t49\t127\t57\t3\t21\t37\t48\t136\n",
            "INFO:__main__:Masking: current score: 0.933888, remaining heads 88 (61.1 percents)\n",
            "INFO:__main__:Heads to mask: [78, 121, 34, 51, 143, 62, 94]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 12:\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\n",
            "Iteration: 100% 90/90 [01:51<00:00,  1.24s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.05092\t0.06530\t0.09470\t0.10387\t0.11708\t0.06575\t0.04923\t0.36112\t0.09939\t0.29079\t0.67976\t0.77363\n",
            "INFO:__main__:layer 2:\t0.14402\t0.15138\t0.06320\t0.08573\t0.33352\t0.10246\t0.95347\t0.17355\t0.13798\t0.33389\t0.25106\t0.13646\n",
            "INFO:__main__:layer 3:\t0.05746\t0.10434\t0.50165\t0.17868\t0.14189\t0.10989\t0.92341\t0.15278\t0.34553\t0.03832\t0.06638\t0.06211\n",
            "INFO:__main__:layer 4:\t0.23821\t0.44792\t0.17466\t0.71938\t0.01824\t0.16795\t0.12205\t0.50084\t0.10688\t0.27598\t0.33376\t0.12517\n",
            "INFO:__main__:layer 5:\t0.13144\t0.38953\t0.30475\t0.22482\t0.23407\t0.19286\t0.56009\t0.38109\t0.12864\t0.51341\t0.14378\t0.37030\n",
            "INFO:__main__:layer 6:\t0.38858\t0.28339\t0.27234\t0.12157\t0.29886\t0.15421\t0.31506\t0.20239\t0.19624\t0.59770\t0.12046\t0.56539\n",
            "INFO:__main__:layer 7:\t1.00000\t0.23821\t0.07866\t0.08360\t0.05793\t0.25672\t0.14031\t0.08534\t0.05841\t0.30691\t0.08544\t0.25575\n",
            "INFO:__main__:layer 8:\t0.12902\t0.34205\t0.30714\t0.17194\t0.25663\t0.89987\t0.26050\t0.06576\t0.00418\t0.06099\t0.26130\t0.21601\n",
            "INFO:__main__:layer 9:\t0.65258\t0.22146\t0.27481\t0.04785\t0.17276\t0.36685\t0.12586\t0.64080\t0.22461\t0.34115\t0.03618\t0.06877\n",
            "INFO:__main__:layer 10:\t0.23803\t0.32696\t0.14808\t0.06312\t0.07203\t0.10015\t0.09201\t0.26028\t0.25391\t0.82171\t0.23271\t0.49439\n",
            "INFO:__main__:layer 11:\t0.76242\t0.28149\t0.18564\t0.01520\t0.00164\t0.00305\t0.08153\t0.12109\t0.24349\t0.08663\t0.74353\t0.05357\n",
            "INFO:__main__:layer 12:\t0.02818\t0.10940\t0.08486\t0.07970\t0.26605\t0.16434\t0.35666\t0.86004\t0.41386\t0.33235\t0.23059\t0.00000\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t132\t123\t107\t103\t98\t122\t133\t27\t106\t42\t10\t6\n",
            "INFO:__main__:layer 2:\t83\t81\t124\t110\t34\t104\t1\t74\t87\t32\t56\t88\n",
            "INFO:__main__:layer 3:\t130\t102\t17\t72\t85\t99\t2\t80\t29\t135\t120\t126\n",
            "INFO:__main__:layer 4:\t59\t20\t73\t9\t138\t77\t94\t18\t101\t45\t33\t93\n",
            "INFO:__main__:layer 5:\t89\t22\t40\t64\t61\t70\t15\t24\t91\t16\t84\t25\n",
            "INFO:__main__:layer 6:\t23\t43\t47\t95\t41\t79\t37\t68\t69\t13\t97\t14\n",
            "INFO:__main__:layer 7:\t0\t58\t117\t114\t129\t52\t86\t112\t128\t39\t111\t54\n",
            "INFO:__main__:layer 8:\t90\t30\t38\t76\t53\t3\t50\t121\t140\t127\t49\t67\n",
            "INFO:__main__:layer 9:\t11\t66\t46\t134\t75\t26\t92\t12\t65\t31\t136\t119\n",
            "INFO:__main__:layer 10:\t60\t36\t82\t125\t118\t105\t108\t51\t55\t5\t62\t19\n",
            "INFO:__main__:layer 11:\t7\t44\t71\t139\t142\t141\t115\t96\t57\t109\t8\t131\n",
            "INFO:__main__:layer 12:\t137\t100\t113\t116\t48\t78\t28\t4\t21\t35\t63\t143\n",
            "INFO:__main__:Masking: current score: 0.931008, remaining heads 81 (56.2 percents)\n",
            "INFO:__main__:Heads to mask: [92, 40, 132, 99, 6, 0, 131]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t1.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\n",
            "Iteration: 100% 90/90 [01:50<00:00,  1.23s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.46743\t0.29989\t0.63717\t0.17982\t0.03971\t0.21543\t0.48922\t0.06329\t0.12979\t0.35670\t0.48555\t0.22686\n",
            "INFO:__main__:layer 2:\t0.26991\t0.44810\t0.33380\t0.22794\t0.06730\t0.22584\t0.31851\t0.32101\t0.25833\t0.13672\t0.09397\t0.82493\n",
            "INFO:__main__:layer 3:\t0.14564\t0.16283\t0.08964\t0.52908\t0.41218\t0.40717\t0.64918\t0.34660\t0.11418\t0.26453\t0.31921\t0.25972\n",
            "INFO:__main__:layer 4:\t0.42871\t0.28267\t0.35338\t0.09169\t0.43690\t0.24580\t0.27316\t0.24823\t0.10890\t0.43986\t0.63393\t0.26373\n",
            "INFO:__main__:layer 5:\t0.01720\t0.33889\t0.43605\t0.37383\t0.45539\t0.22969\t0.40705\t0.30381\t0.11430\t0.48784\t0.35541\t0.34439\n",
            "INFO:__main__:layer 6:\t0.41361\t0.27841\t0.33794\t0.17234\t0.29753\t0.22531\t0.50633\t0.31686\t0.35933\t0.13206\t0.13609\t0.63826\n",
            "INFO:__main__:layer 7:\t0.88147\t0.28398\t0.07846\t0.21736\t0.10795\t0.41666\t0.36088\t0.10648\t0.14819\t0.29171\t0.19031\t0.30934\n",
            "INFO:__main__:layer 8:\t0.07417\t0.40495\t0.14317\t0.09433\t0.03003\t0.90936\t0.45026\t0.24751\t0.36398\t0.03835\t0.14667\t0.20344\n",
            "INFO:__main__:layer 9:\t0.57187\t0.04250\t0.98791\t0.12612\t0.08729\t0.07548\t0.11352\t0.15602\t0.24827\t0.10073\t0.10455\t0.21016\n",
            "INFO:__main__:layer 10:\t0.04431\t0.87589\t0.29702\t0.00874\t0.02100\t0.05533\t0.01854\t0.16360\t0.16872\t0.49275\t0.57915\t0.06782\n",
            "INFO:__main__:layer 11:\t0.36932\t0.12802\t0.05035\t0.00000\t0.00868\t0.10145\t0.01222\t0.49960\t0.23437\t0.04604\t0.18143\t1.00000\n",
            "INFO:__main__:layer 12:\t0.19125\t0.25681\t0.02232\t0.14610\t0.08981\t0.35936\t0.42302\t0.50924\t0.86599\t0.04068\t0.15917\t0.09413\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t21\t56\t9\t87\t133\t81\t18\t126\t102\t42\t20\t77\n",
            "INFO:__main__:layer 2:\t64\t24\t49\t76\t125\t78\t52\t50\t68\t99\t116\t6\n",
            "INFO:__main__:layer 3:\t97\t91\t119\t13\t32\t33\t7\t45\t106\t65\t51\t67\n",
            "INFO:__main__:layer 4:\t28\t61\t44\t117\t26\t73\t63\t71\t108\t25\t10\t66\n",
            "INFO:__main__:layer 5:\t139\t47\t27\t36\t22\t75\t34\t55\t105\t19\t43\t46\n",
            "INFO:__main__:layer 6:\t31\t62\t48\t88\t57\t79\t15\t53\t41\t101\t100\t8\n",
            "INFO:__main__:layer 7:\t3\t60\t121\t80\t109\t30\t39\t110\t94\t59\t85\t54\n",
            "INFO:__main__:layer 8:\t123\t35\t98\t114\t135\t2\t23\t72\t38\t134\t95\t83\n",
            "INFO:__main__:layer 9:\t12\t131\t1\t104\t120\t122\t107\t93\t70\t113\t111\t82\n",
            "INFO:__main__:layer 10:\t130\t4\t58\t141\t137\t127\t138\t90\t89\t17\t11\t124\n",
            "INFO:__main__:layer 11:\t37\t103\t128\t143\t142\t112\t140\t16\t74\t129\t86\t0\n",
            "INFO:__main__:layer 12:\t84\t69\t136\t96\t118\t40\t29\t14\t5\t132\t92\t115\n",
            "INFO:__main__:Masking: current score: 0.924630, remaining heads 74 (51.4 percents)\n",
            "INFO:__main__:Heads to mask: [48, 134, 88, 4, 141, 108, 7]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\n",
            "Iteration: 100% 90/90 [01:50<00:00,  1.23s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.29293\t0.25079\t0.40402\t0.23772\t0.10218\t0.17232\t0.09360\t0.38958\t0.07516\t0.04957\t0.48398\t0.42658\n",
            "INFO:__main__:layer 2:\t0.64670\t0.22953\t0.25306\t0.06922\t0.16373\t0.20804\t0.01723\t0.31597\t0.32622\t0.33872\t0.03458\t0.25248\n",
            "INFO:__main__:layer 3:\t0.06831\t0.00586\t0.16612\t0.10672\t0.09831\t0.91182\t0.24529\t0.11364\t0.18763\t0.09282\t0.04992\t0.08554\n",
            "INFO:__main__:layer 4:\t0.17241\t0.09895\t0.18717\t0.17885\t0.22651\t0.23263\t0.14843\t0.06635\t0.59871\t0.11490\t0.56089\t0.26731\n",
            "INFO:__main__:layer 5:\t1.00000\t0.04973\t0.04542\t0.03423\t0.08390\t0.01697\t0.02576\t0.01117\t0.01370\t0.04783\t0.04391\t0.08712\n",
            "INFO:__main__:layer 6:\t0.51185\t0.20533\t0.20535\t0.07057\t0.13685\t0.21154\t0.35933\t0.26936\t0.31033\t0.18329\t0.10735\t0.48367\n",
            "INFO:__main__:layer 7:\t0.68205\t0.26928\t0.03088\t0.18595\t0.04524\t0.15334\t0.06691\t0.18635\t0.10944\t0.40170\t0.11497\t0.41900\n",
            "INFO:__main__:layer 8:\t0.07706\t0.18803\t0.06318\t0.45213\t0.13901\t0.51794\t0.47271\t0.05769\t0.34626\t0.00804\t0.33217\t0.06729\n",
            "INFO:__main__:layer 9:\t0.18735\t0.01668\t0.93746\t0.06684\t0.01861\t0.07651\t0.01869\t0.02842\t0.06638\t0.02767\t0.03378\t0.29461\n",
            "INFO:__main__:layer 10:\t0.48761\t0.35064\t0.37695\t0.00549\t0.07487\t0.05270\t0.01617\t0.12450\t0.16959\t0.41420\t0.51425\t0.09000\n",
            "INFO:__main__:layer 11:\t0.41448\t0.10180\t0.00000\t0.00955\t0.03249\t0.04930\t0.00958\t0.53995\t0.11347\t0.05223\t0.11620\t0.71038\n",
            "INFO:__main__:layer 12:\t0.15867\t0.21773\t0.23518\t0.11300\t0.01793\t0.20811\t0.32664\t0.36744\t0.72339\t0.15537\t0.14427\t0.06636\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t37\t43\t22\t45\t86\t65\t90\t24\t98\t115\t14\t18\n",
            "INFO:__main__:layer 2:\t6\t48\t41\t101\t68\t53\t132\t34\t33\t30\t121\t42\n",
            "INFO:__main__:layer 3:\t102\t141\t67\t85\t89\t2\t44\t80\t57\t91\t113\t94\n",
            "INFO:__main__:layer 4:\t64\t88\t59\t63\t49\t47\t72\t108\t7\t79\t8\t40\n",
            "INFO:__main__:layer 5:\t0\t114\t118\t122\t95\t133\t128\t137\t136\t117\t120\t93\n",
            "INFO:__main__:layer 6:\t12\t55\t54\t100\t75\t51\t27\t38\t35\t62\t84\t15\n",
            "INFO:__main__:layer 7:\t5\t39\t125\t61\t119\t71\t104\t60\t83\t23\t78\t19\n",
            "INFO:__main__:layer 8:\t96\t56\t109\t17\t74\t10\t16\t110\t29\t140\t31\t103\n",
            "INFO:__main__:layer 9:\t58\t134\t1\t105\t130\t97\t129\t126\t106\t127\t123\t36\n",
            "INFO:__main__:layer 10:\t13\t28\t25\t142\t99\t111\t135\t76\t66\t21\t11\t92\n",
            "INFO:__main__:layer 11:\t20\t87\t143\t139\t124\t116\t138\t9\t81\t112\t77\t4\n",
            "INFO:__main__:layer 12:\t69\t50\t46\t82\t131\t52\t32\t26\t3\t70\t73\t107\n",
            "INFO:__main__:Masking: current score: 0.903909, remaining heads 67 (46.5 percents)\n",
            "INFO:__main__:Heads to mask: [25, 55, 18, 22, 58, 76, 9]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\n",
            "Iteration: 100% 90/90 [01:50<00:00,  1.23s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.23989\t0.20807\t0.37050\t0.29856\t0.13200\t0.25255\t0.08776\t0.23167\t0.13445\t0.24132\t0.23541\t0.67284\n",
            "INFO:__main__:layer 2:\t0.38886\t0.20224\t0.23824\t0.10223\t0.32524\t0.27111\t0.46168\t0.35296\t0.24331\t0.30301\t0.28859\t0.20631\n",
            "INFO:__main__:layer 3:\t0.10040\t0.09240\t0.25737\t0.04941\t0.07062\t0.94241\t0.10297\t0.12455\t0.16197\t0.10669\t0.06557\t0.09738\n",
            "INFO:__main__:layer 4:\t0.08098\t0.03488\t0.12409\t0.21518\t0.16565\t0.18547\t0.13886\t0.23500\t0.66878\t0.04406\t0.53518\t0.33788\n",
            "INFO:__main__:layer 5:\t1.00000\t0.05416\t0.05661\t0.04357\t0.10252\t0.01879\t0.01780\t0.04026\t0.01170\t0.05353\t0.08857\t0.16813\n",
            "INFO:__main__:layer 6:\t0.70536\t0.09782\t0.13154\t0.00874\t0.02139\t0.02760\t0.05670\t0.18454\t0.20216\t0.61840\t0.05133\t0.26132\n",
            "INFO:__main__:layer 7:\t0.58364\t0.25928\t0.07368\t0.05652\t0.25627\t0.14100\t0.02612\t0.46094\t0.04273\t0.50948\t0.14584\t0.24008\n",
            "INFO:__main__:layer 8:\t0.16680\t0.05229\t0.02807\t0.52472\t0.13049\t0.05214\t0.77471\t0.11711\t0.26334\t0.04246\t0.21368\t0.00536\n",
            "INFO:__main__:layer 9:\t0.14296\t0.00960\t0.98441\t0.05862\t0.00000\t0.02582\t0.00034\t0.12083\t0.09647\t0.01256\t0.05848\t0.19639\n",
            "INFO:__main__:layer 10:\t0.69555\t0.36757\t0.24201\t0.08230\t0.04493\t0.17763\t0.01884\t0.20573\t0.01207\t0.10576\t0.22880\t0.48150\n",
            "INFO:__main__:layer 11:\t0.57515\t0.14935\t0.05521\t0.02683\t0.03165\t0.01995\t0.03780\t0.59253\t0.03117\t0.00353\t0.05212\t0.58607\n",
            "INFO:__main__:layer 12:\t0.17657\t0.22551\t0.14294\t0.12240\t0.16107\t0.29855\t0.28620\t0.12913\t0.83240\t0.07770\t0.11920\t0.10817\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t42\t51\t21\t27\t73\t37\t95\t46\t72\t40\t44\t7\n",
            "INFO:__main__:layer 2:\t20\t54\t43\t88\t25\t31\t18\t23\t38\t26\t29\t52\n",
            "INFO:__main__:layer 3:\t89\t93\t35\t114\t100\t2\t86\t77\t64\t84\t101\t91\n",
            "INFO:__main__:layer 4:\t97\t122\t78\t49\t63\t57\t71\t45\t8\t116\t14\t24\n",
            "INFO:__main__:layer 5:\t0\t108\t105\t117\t87\t133\t134\t120\t137\t109\t94\t61\n",
            "INFO:__main__:layer 6:\t5\t90\t74\t139\t130\t126\t104\t58\t55\t9\t113\t33\n",
            "INFO:__main__:layer 7:\t12\t34\t99\t106\t36\t70\t128\t19\t118\t16\t67\t41\n",
            "INFO:__main__:layer 8:\t62\t110\t125\t15\t75\t111\t4\t82\t32\t119\t50\t140\n",
            "INFO:__main__:layer 9:\t68\t138\t1\t102\t143\t129\t142\t80\t92\t135\t103\t56\n",
            "INFO:__main__:layer 10:\t6\t22\t39\t96\t115\t59\t132\t53\t136\t85\t47\t17\n",
            "INFO:__main__:layer 11:\t13\t66\t107\t127\t123\t131\t121\t10\t124\t141\t112\t11\n",
            "INFO:__main__:layer 12:\t60\t48\t69\t79\t65\t28\t30\t76\t3\t98\t81\t83\n",
            "INFO:__main__:Masking: current score: 0.896959, remaining heads 60 (41.7 percents)\n",
            "INFO:__main__:Heads to mask: [95, 116, 65, 128, 80, 27, 130]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\n",
            "Iteration: 100% 90/90 [01:50<00:00,  1.22s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.28859\t0.20077\t0.36505\t0.40799\t0.15254\t0.26624\t0.12102\t0.12592\t0.16231\t0.17916\t0.40196\t0.52861\n",
            "INFO:__main__:layer 2:\t0.48792\t0.19908\t0.21664\t0.14942\t0.16980\t0.22851\t0.41203\t0.34851\t0.15984\t0.30780\t0.27911\t0.35949\n",
            "INFO:__main__:layer 3:\t0.10473\t0.08170\t0.12433\t0.26474\t0.08660\t0.92362\t0.16676\t0.12369\t0.15847\t0.10347\t0.07045\t0.07443\n",
            "INFO:__main__:layer 4:\t0.13312\t0.08361\t0.15552\t0.11044\t0.13172\t0.19089\t0.18196\t0.46509\t0.61793\t0.08590\t0.43121\t0.33124\n",
            "INFO:__main__:layer 5:\t1.00000\t0.05980\t0.05192\t0.04318\t0.11321\t0.03208\t0.04742\t0.01643\t0.02213\t0.05625\t0.10561\t0.13300\n",
            "INFO:__main__:layer 6:\t0.81003\t0.14646\t0.12660\t0.05807\t0.10915\t0.24133\t0.17460\t0.16725\t0.32115\t0.28212\t0.06686\t0.19431\n",
            "INFO:__main__:layer 7:\t0.73840\t0.21314\t0.07941\t0.04632\t0.23078\t0.07813\t0.12666\t0.15403\t0.20627\t0.43018\t0.21610\t0.27820\n",
            "INFO:__main__:layer 8:\t0.05739\t0.13431\t0.08191\t0.77681\t0.37834\t0.05438\t0.22408\t0.01763\t0.22100\t0.01580\t0.41019\t0.08172\n",
            "INFO:__main__:layer 9:\t0.06712\t0.00003\t0.97335\t0.00836\t0.00202\t0.07860\t0.00334\t0.02490\t0.00000\t0.00541\t0.02555\t0.31407\n",
            "INFO:__main__:layer 10:\t0.33625\t0.52035\t0.42641\t0.01449\t0.06081\t0.02101\t0.01392\t0.45630\t0.16263\t0.23381\t0.35877\t0.24771\n",
            "INFO:__main__:layer 11:\t0.28601\t0.17454\t0.00498\t0.01290\t0.04357\t0.02951\t0.01101\t0.41356\t0.15963\t0.04775\t0.65458\t0.55666\n",
            "INFO:__main__:layer 12:\t0.17546\t0.19033\t0.07597\t0.12663\t0.01587\t0.21560\t0.38376\t0.32325\t0.77568\t0.16522\t0.16642\t0.08124\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t35\t54\t25\t21\t76\t40\t89\t86\t70\t60\t22\t10\n",
            "INFO:__main__:layer 2:\t12\t55\t49\t77\t64\t46\t19\t28\t71\t34\t38\t26\n",
            "INFO:__main__:layer 3:\t94\t101\t87\t41\t96\t2\t66\t88\t73\t95\t108\t107\n",
            "INFO:__main__:layer 4:\t80\t98\t74\t91\t82\t57\t59\t13\t8\t97\t15\t30\n",
            "INFO:__main__:layer 5:\t0\t112\t117\t122\t90\t123\t119\t130\t127\t115\t93\t81\n",
            "INFO:__main__:layer 6:\t3\t78\t85\t113\t92\t43\t62\t65\t32\t37\t110\t56\n",
            "INFO:__main__:layer 7:\t6\t52\t103\t120\t45\t105\t83\t75\t53\t16\t50\t39\n",
            "INFO:__main__:layer 8:\t114\t79\t99\t4\t24\t116\t47\t129\t48\t132\t20\t100\n",
            "INFO:__main__:layer 9:\t109\t142\t1\t137\t141\t104\t140\t126\t143\t138\t125\t33\n",
            "INFO:__main__:layer 10:\t29\t11\t17\t133\t111\t128\t134\t14\t69\t44\t27\t42\n",
            "INFO:__main__:layer 11:\t36\t63\t139\t135\t121\t124\t136\t18\t72\t118\t7\t9\n",
            "INFO:__main__:layer 12:\t61\t58\t106\t84\t131\t51\t23\t31\t5\t68\t67\t102\n",
            "INFO:__main__:Masking: current score: 0.879778, remaining heads 53 (36.8 percents)\n",
            "INFO:__main__:Heads to mask: [75, 89, 84, 35, 77, 24, 39]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\n",
            "Iteration: 100% 90/90 [01:50<00:00,  1.22s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.16239\t0.29258\t0.41392\t0.24339\t0.11965\t0.05169\t0.16503\t0.59854\t0.09441\t0.13781\t0.52173\t0.06334\n",
            "INFO:__main__:layer 2:\t0.76548\t0.19901\t0.17688\t0.08722\t0.08331\t0.13308\t0.14547\t0.33402\t0.07715\t0.16381\t0.32369\t0.30025\n",
            "INFO:__main__:layer 3:\t0.26368\t0.07297\t0.04724\t0.30449\t0.08291\t0.86269\t0.28605\t0.10272\t0.09449\t0.05980\t0.06942\t0.14570\n",
            "INFO:__main__:layer 4:\t0.21477\t0.17433\t0.27522\t0.62631\t0.13729\t0.20799\t0.15751\t0.13821\t0.50554\t0.14148\t0.31638\t0.14787\n",
            "INFO:__main__:layer 5:\t1.00000\t0.08400\t0.05530\t0.05935\t0.10186\t0.04130\t0.08158\t0.04253\t0.02344\t0.08895\t0.11223\t0.02237\n",
            "INFO:__main__:layer 6:\t0.30277\t0.09229\t0.11064\t0.06041\t0.21284\t0.35250\t0.35750\t0.11821\t0.15372\t0.38165\t0.07555\t0.66827\n",
            "INFO:__main__:layer 7:\t0.90443\t0.15916\t0.04490\t0.17403\t0.18491\t0.21725\t0.18048\t0.13436\t0.07443\t0.14165\t0.10666\t0.08437\n",
            "INFO:__main__:layer 8:\t0.16967\t0.19768\t0.12828\t0.05606\t0.22079\t0.94149\t0.06525\t0.07159\t0.09059\t0.00314\t0.07704\t0.08562\n",
            "INFO:__main__:layer 9:\t0.16247\t0.01915\t0.93816\t0.02210\t0.04327\t0.04298\t0.02677\t0.10944\t0.01109\t0.03428\t0.00875\t0.36081\n",
            "INFO:__main__:layer 10:\t0.03955\t0.28728\t0.35953\t0.02632\t0.00785\t0.05478\t0.01413\t0.05096\t0.26568\t0.81030\t0.32292\t0.03417\n",
            "INFO:__main__:layer 11:\t0.22306\t0.11514\t0.07980\t0.00000\t0.04342\t0.04963\t0.01988\t0.18019\t0.30296\t0.07205\t0.81262\t0.43389\n",
            "INFO:__main__:layer 12:\t0.14725\t0.17682\t0.17848\t0.07806\t0.20963\t0.08683\t0.40022\t0.49716\t0.56037\t0.31123\t0.29089\t0.05627\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t61\t32\t16\t39\t77\t118\t58\t10\t87\t72\t12\t110\n",
            "INFO:__main__:layer 2:\t7\t47\t53\t91\t96\t75\t68\t23\t101\t59\t24\t31\n",
            "INFO:__main__:layer 3:\t38\t105\t121\t28\t97\t4\t35\t84\t86\t112\t108\t67\n",
            "INFO:__main__:layer 4:\t43\t55\t36\t9\t73\t46\t63\t71\t13\t70\t26\t65\n",
            "INFO:__main__:layer 5:\t0\t95\t116\t113\t85\t127\t98\t126\t133\t90\t80\t134\n",
            "INFO:__main__:layer 6:\t30\t88\t81\t111\t44\t22\t21\t78\t64\t18\t103\t8\n",
            "INFO:__main__:layer 7:\t3\t62\t122\t56\t49\t42\t50\t74\t104\t69\t83\t94\n",
            "INFO:__main__:layer 8:\t57\t48\t76\t115\t41\t1\t109\t107\t89\t142\t102\t93\n",
            "INFO:__main__:layer 9:\t60\t137\t2\t135\t124\t125\t131\t82\t139\t129\t140\t19\n",
            "INFO:__main__:layer 10:\t128\t34\t20\t132\t141\t117\t138\t119\t37\t6\t25\t130\n",
            "INFO:__main__:layer 11:\t40\t79\t99\t143\t123\t120\t136\t51\t29\t106\t5\t15\n",
            "INFO:__main__:layer 12:\t66\t54\t52\t100\t45\t92\t17\t14\t11\t27\t33\t114\n",
            "INFO:__main__:Masking: current score: 0.871429, remaining heads 46 (31.9 percents)\n",
            "INFO:__main__:Heads to mask: [59, 26, 115, 5, 87, 11, 90]\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\n",
            "Iteration: 100% 90/90 [01:50<00:00,  1.22s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.14525\t0.04074\t0.34773\t0.16931\t0.21069\t0.29352\t0.23281\t0.05458\t0.22514\t0.31537\t0.63877\t0.39596\n",
            "INFO:__main__:layer 2:\t0.50576\t0.09149\t0.09939\t0.13395\t0.36578\t0.27148\t0.36404\t0.29387\t0.06593\t0.02467\t0.42793\t0.41076\n",
            "INFO:__main__:layer 3:\t0.32549\t0.02264\t0.13069\t0.12512\t0.05674\t0.93676\t0.13291\t0.09154\t0.06469\t0.11067\t0.05196\t0.13422\n",
            "INFO:__main__:layer 4:\t0.12068\t0.01156\t0.12921\t0.08889\t0.07525\t0.22364\t0.05151\t0.47179\t0.77840\t0.04895\t0.33129\t0.20406\n",
            "INFO:__main__:layer 5:\t1.00000\t0.06908\t0.05017\t0.04956\t0.11924\t0.04294\t0.06414\t0.00499\t0.02067\t0.05590\t0.08492\t0.21479\n",
            "INFO:__main__:layer 6:\t0.63916\t0.09581\t0.20607\t0.06680\t0.25070\t0.36392\t0.37101\t0.25387\t0.37501\t0.08346\t0.12608\t0.22283\n",
            "INFO:__main__:layer 7:\t0.94530\t0.14605\t0.07321\t0.06850\t0.07438\t0.20585\t0.15767\t0.13079\t0.01694\t0.16438\t0.15458\t0.12776\n",
            "INFO:__main__:layer 8:\t0.11851\t0.18028\t0.14109\t0.13007\t0.27094\t0.79795\t0.42887\t0.04985\t0.11029\t0.02000\t0.27830\t0.09580\n",
            "INFO:__main__:layer 9:\t0.18924\t0.00503\t0.99403\t0.01521\t0.03235\t0.21444\t0.01018\t0.00000\t0.01675\t0.01061\t0.00271\t0.12878\n",
            "INFO:__main__:layer 10:\t0.45087\t0.59260\t0.36867\t0.10069\t0.01158\t0.05719\t0.04297\t0.08562\t0.17351\t0.26178\t0.44879\t0.25282\n",
            "INFO:__main__:layer 11:\t0.29341\t0.12397\t0.04137\t0.00548\t0.06098\t0.02696\t0.00613\t0.69121\t0.17428\t0.04880\t0.36033\t0.57707\n",
            "INFO:__main__:layer 12:\t0.16481\t0.17855\t0.01637\t0.13157\t0.07720\t0.18803\t0.39477\t0.35523\t0.78819\t0.09963\t0.19862\t0.08930\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t66\t123\t29\t60\t49\t34\t43\t112\t44\t32\t9\t19\n",
            "INFO:__main__:layer 2:\t12\t92\t88\t69\t24\t37\t25\t33\t105\t126\t17\t18\n",
            "INFO:__main__:layer 3:\t31\t127\t73\t79\t110\t3\t70\t91\t106\t84\t113\t68\n",
            "INFO:__main__:layer 4:\t81\t135\t75\t94\t99\t45\t114\t13\t6\t118\t30\t52\n",
            "INFO:__main__:layer 5:\t0\t102\t115\t117\t82\t121\t107\t141\t128\t111\t96\t47\n",
            "INFO:__main__:layer 6:\t8\t89\t50\t104\t42\t26\t22\t40\t21\t97\t78\t46\n",
            "INFO:__main__:layer 7:\t2\t65\t101\t103\t100\t51\t63\t72\t130\t62\t64\t77\n",
            "INFO:__main__:layer 8:\t83\t56\t67\t74\t38\t4\t16\t116\t85\t129\t36\t90\n",
            "INFO:__main__:layer 9:\t54\t140\t1\t133\t124\t48\t137\t143\t131\t136\t142\t76\n",
            "INFO:__main__:layer 10:\t14\t10\t23\t86\t134\t109\t120\t95\t59\t39\t15\t41\n",
            "INFO:__main__:layer 11:\t35\t80\t122\t139\t108\t125\t138\t7\t58\t119\t27\t11\n",
            "INFO:__main__:layer 12:\t61\t57\t132\t71\t98\t55\t20\t28\t5\t87\t53\t93\n",
            "INFO:__main__:Masking: current score: 0.846928, remaining heads 39 (27.1 percents)\n",
            "INFO:__main__:Final head mask\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\n",
            "INFO:__main__:layer 2:\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\t1.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 6:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 7:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t1.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t1.00000\t0.00000\t1.00000\t1.00000\t0.00000\t1.00000\t0.00000\t1.00000\t0.00000\n",
            "Iteration: 100% 90/90 [01:50<00:00,  1.23s/it]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 2:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 3:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 4:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 5:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 6:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 7:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 8:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 9:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 10:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 11:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 12:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t42\t43\t41\t40\t45\t44\t46\t47\t37\t36\t38\t39\n",
            "INFO:__main__:layer 2:\t34\t35\t33\t32\t53\t52\t54\t55\t50\t51\t49\t48\n",
            "INFO:__main__:layer 3:\t58\t59\t57\t56\t61\t60\t62\t63\t21\t20\t22\t23\n",
            "INFO:__main__:layer 4:\t18\t19\t17\t16\t26\t27\t25\t24\t29\t28\t30\t31\n",
            "INFO:__main__:layer 5:\t10\t11\t9\t8\t13\t12\t14\t15\t5\t4\t6\t7\n",
            "INFO:__main__:layer 6:\t2\t3\t1\t0\t85\t84\t86\t87\t82\t83\t81\t80\n",
            "INFO:__main__:layer 7:\t90\t91\t89\t88\t93\t92\t94\t95\t74\t75\t73\t72\n",
            "INFO:__main__:layer 8:\t77\t76\t78\t79\t69\t68\t70\t71\t66\t67\t65\t64\n",
            "INFO:__main__:layer 9:\t106\t107\t105\t104\t109\t108\t110\t111\t101\t100\t102\t103\n",
            "INFO:__main__:layer 10:\t98\t99\t97\t96\t133\t132\t134\t135\t130\t131\t129\t128\n",
            "INFO:__main__:layer 11:\t138\t139\t137\t136\t141\t140\t142\t143\t117\t116\t118\t119\n",
            "INFO:__main__:layer 12:\t114\t115\t113\t112\t122\t123\t121\t120\t125\t124\t126\t127\n",
            "Iteration: 100% 90/90 [01:23<00:00,  1.08it/s]\n",
            "INFO:__main__:Attention entropies\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 2:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 3:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 4:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 5:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 6:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 7:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 8:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 9:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 10:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 11:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:layer 12:\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\t0.00000\n",
            "INFO:__main__:Head importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 2:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 3:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 4:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 5:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 6:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 7:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 8:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 9:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 10:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 11:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:layer 12:\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\tnan\n",
            "INFO:__main__:Head ranked by importance scores\n",
            "INFO:__main__:lv, h >\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\n",
            "INFO:__main__:layer 1:\t42\t43\t41\t40\t45\t44\t46\t47\t37\t36\t38\t39\n",
            "INFO:__main__:layer 2:\t34\t35\t33\t32\t53\t52\t54\t55\t50\t51\t49\t48\n",
            "INFO:__main__:layer 3:\t58\t59\t57\t56\t61\t60\t62\t63\t21\t20\t22\t23\n",
            "INFO:__main__:layer 4:\t18\t19\t17\t16\t26\t27\t25\t24\t29\t28\t30\t31\n",
            "INFO:__main__:layer 5:\t10\t11\t9\t8\t13\t12\t14\t15\t5\t4\t6\t7\n",
            "INFO:__main__:layer 6:\t2\t3\t1\t0\t85\t84\t86\t87\t82\t83\t81\t80\n",
            "INFO:__main__:layer 7:\t90\t91\t89\t88\t93\t92\t94\t95\t74\t75\t73\t72\n",
            "INFO:__main__:layer 8:\t77\t76\t78\t79\t69\t68\t70\t71\t66\t67\t65\t64\n",
            "INFO:__main__:layer 9:\t106\t107\t105\t104\t109\t108\t110\t111\t101\t100\t102\t103\n",
            "INFO:__main__:layer 10:\t98\t99\t97\t96\t133\t132\t134\t135\t130\t131\t129\t128\n",
            "INFO:__main__:layer 11:\t138\t139\t137\t136\t141\t140\t142\t143\t117\t116\t118\t119\n",
            "INFO:__main__:layer 12:\t114\t115\t113\t112\t122\t123\t121\t120\t125\t124\t126\t127\n",
            "INFO:__main__:Pruning: original num of params: 1.08e+08, after pruning 8.90e+07 (82.2 percents)\n",
            "INFO:__main__:Pruning: score with masking: 0.868284 score with pruning: 0.869250\n",
            "INFO:__main__:Pruning: original timing:  110.288428\n",
            "INFO:__main__:Pruning: new timing:  83.045930\n",
            "INFO:__main__:Pruning: speed ratio (new timing / original timing): 132.804134 percents\n",
            "[INFO|trainer.py:726] 2022-10-25 14:37:16,969 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2925] 2022-10-25 14:37:16,970 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2927] 2022-10-25 14:37:16,971 >>   Num examples = 1500\n",
            "[INFO|trainer.py:2930] 2022-10-25 14:37:16,971 >>   Batch size = 256\n",
            "100% 6/6 [00:06<00:00,  1.12s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_combined_score     =     0.8626\n",
            "  eval_loss               =     0.6725\n",
            "  eval_pearson            =     0.8636\n",
            "  eval_runtime            = 0:00:08.08\n",
            "  eval_samples            =       1500\n",
            "  eval_samples_per_second =    185.477\n",
            "  eval_spearmanr          =     0.8617\n",
            "  eval_steps_per_second   =      0.742\n",
            "  size_of                 =  356106756\n"
          ]
        }
      ],
      "source": [
        "!python ./run_glue_prun_final.py \\\n",
        "  --model_name_or_path bert-base-cased \\\n",
        "  --task_name stsb \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --max_seq_length 128 \\\n",
        "  --per_device_train_batch_size 64 \\\n",
        "  --per_device_eval_batch_size 256 \\\n",
        "  --learning_rate 5e-5 \\\n",
        "  --num_train_epochs 3 \\\n",
        "  --seed 1337 \\\n",
        "  --run_name \"test_32_off\" \\\n",
        "  --output_dir \"glue_bert_prune\" \\\n",
        "  --try_masking \\\n",
        "  --masking_threshold 0.9 \\\n",
        "  --masking_amount 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-CvpDua_nPH",
        "outputId": "bcc55bf7-b095-4879-ea24-266a970e0fcc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/glue_bert_prune were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained('/content/glue_bert_prune')\n",
        "model = AutoModel.from_pretrained(\"/content/glue_bert_prune\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaouCy3LlePI"
      },
      "outputs": [],
      "source": [
        "masked_heads = torch.tensor(np.load('/content/glue_bert_prune/head_mask.npy'))\n",
        "\n",
        "#we need at least one alive head at layer\n",
        "for i in np.where(np.all(np.isclose(masked_heads, 0), axis=1))[0]:\n",
        "    masked_heads[i][0] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT5MSEfYlu6T",
        "outputId": "f1f98a04-010c-46df-f421-5089d8cf8f48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: [1, 4, 6, 7, 10, 11],\n",
              " 1: [0, 6, 7, 8, 10, 11],\n",
              " 2: [3, 4, 5, 10],\n",
              " 3: [0, 1, 9, 10, 11],\n",
              " 4: [0, 2, 4, 7],\n",
              " 5: [0, 3, 7, 8, 10, 11],\n",
              " 6: [0, 2, 3, 6, 8],\n",
              " 7: [2, 4, 9, 10, 11],\n",
              " 8: [3, 5, 6, 8],\n",
              " 9: [3, 6, 7],\n",
              " 10: [3, 4, 5, 7, 8, 9],\n",
              " 11: [6, 10, 11]}"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "heads_to_prune = dict(\n",
        "        (layer, torch.atleast_1d((1 - head_mask[layer].long()).nonzero().squeeze()).tolist()) for layer in range(len(head_mask))\n",
        "    )\n",
        "heads_to_prune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRwIjXEVl3-c",
        "outputId": "2eaafac7-7194-4d68-c121-2a6544fd6a98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "413.1787109375"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_memory_footprint() / 1024 / 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLIet5IWl0Iq"
      },
      "outputs": [],
      "source": [
        "model.prune_heads(heads_to_prune)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixTmvSXyl6FE",
        "outputId": "35548947-f774-4d04-cfb3-ebc937ff8692"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "370.386962890625"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_memory_footprint() / 1024 / 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2BOmd-el98O",
        "outputId": "3445c3e4-4c7e-42be-e04f-b6c3245bed8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('pruned_bert/tokenizer_config.json',\n",
              " 'pruned_bert/special_tokens_map.json',\n",
              " 'pruned_bert/vocab.txt',\n",
              " 'pruned_bert/added_tokens.json',\n",
              " 'pruned_bert/tokenizer.json')"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained('pruned_bert')\n",
        "tokenizer.save_pretrained('pruned_bert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLF7PmvxmdPA",
        "outputId": "0471053f-2a58-454f-e3a3-8fcf458a6e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "WARNING:__main__:Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "INFO:__main__:Training/evaluation parameters PruneTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "dont_normalize_global_importance=False,\n",
            "dont_normalize_importance_by_layer=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=passive,\n",
            "log_on_each_node=True,\n",
            "logging_dir=glue_bert_prune/runs/Oct25_14-49-02_217af3205d69,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "masking_amount=0.1,\n",
            "masking_threshold=0.9,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_hf,\n",
            "output_dir=glue_bert_prune,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=256,\n",
            "per_device_train_batch_size=64,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=test_32_off,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=1337,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "try_masking=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\n",
            "INFO:datasets.builder:Overwrite dataset info from restored data version.\n",
            "INFO:datasets.info:Loading Dataset info from /root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\n",
            "WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "INFO:datasets.info:Loading Dataset info from /root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\n",
            "100% 3/3 [00:00<00:00, 873.93it/s]\n",
            "[INFO|configuration_utils.py:651] 2022-10-25 14:49:07,170 >> loading configuration file pruned_bert/config.json\n",
            "[INFO|configuration_utils.py:705] 2022-10-25 14:49:07,171 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"pruned_bert\",\n",
            "  \"architectures\": [\n",
            "    \"BertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"stsb\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"regression\",\n",
            "  \"pruned_heads\": {\n",
            "    \"0\": [\n",
            "      1,\n",
            "      4,\n",
            "      6,\n",
            "      7,\n",
            "      10,\n",
            "      11\n",
            "    ],\n",
            "    \"1\": [\n",
            "      0,\n",
            "      6,\n",
            "      7,\n",
            "      8,\n",
            "      10,\n",
            "      11\n",
            "    ],\n",
            "    \"2\": [\n",
            "      10,\n",
            "      3,\n",
            "      4,\n",
            "      5\n",
            "    ],\n",
            "    \"3\": [\n",
            "      0,\n",
            "      1,\n",
            "      9,\n",
            "      10,\n",
            "      11\n",
            "    ],\n",
            "    \"4\": [\n",
            "      0,\n",
            "      2,\n",
            "      4,\n",
            "      7\n",
            "    ],\n",
            "    \"5\": [\n",
            "      0,\n",
            "      3,\n",
            "      7,\n",
            "      8,\n",
            "      10,\n",
            "      11\n",
            "    ],\n",
            "    \"6\": [\n",
            "      0,\n",
            "      2,\n",
            "      3,\n",
            "      6,\n",
            "      8\n",
            "    ],\n",
            "    \"7\": [\n",
            "      2,\n",
            "      4,\n",
            "      9,\n",
            "      10,\n",
            "      11\n",
            "    ],\n",
            "    \"8\": [\n",
            "      8,\n",
            "      3,\n",
            "      5,\n",
            "      6\n",
            "    ],\n",
            "    \"9\": [\n",
            "      3,\n",
            "      6,\n",
            "      7\n",
            "    ],\n",
            "    \"10\": [\n",
            "      3,\n",
            "      4,\n",
            "      5,\n",
            "      7,\n",
            "      8,\n",
            "      9\n",
            "    ],\n",
            "    \"11\": [\n",
            "      10,\n",
            "      11,\n",
            "      6\n",
            "    ]\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.24.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-10-25 14:49:07,172 >> loading file vocab.txt\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-10-25 14:49:07,172 >> loading file tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-10-25 14:49:07,172 >> loading file added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-10-25 14:49:07,172 >> loading file special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-10-25 14:49:07,172 >> loading file tokenizer_config.json\n",
            "[INFO|modeling_utils.py:2153] 2022-10-25 14:49:07,197 >> loading weights file pruned_bert/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:2606] 2022-10-25 14:49:08,722 >> All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "[WARNING|modeling_utils.py:2609] 2022-10-25 14:49:08,722 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at pruned_bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-2ff0399dd5bc8a3b.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-0e37164a033718da.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-d3625e9cba6b5431.arrow\n",
            "INFO:__main__:*** Evaluate ***\n",
            "[INFO|trainer.py:726] 2022-10-25 14:49:12,552 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx. If sentence1, sentence2, idx are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2925] 2022-10-25 14:49:12,554 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2927] 2022-10-25 14:49:12,554 >>   Num examples = 1500\n",
            "[INFO|trainer.py:2930] 2022-10-25 14:49:12,554 >>   Batch size = 256\n",
            "100% 6/6 [00:07<00:00,  1.33s/it]\n",
            "***** eval metrics *****\n",
            "  eval_combined_score     =    -0.7987\n",
            "  eval_loss               =     7.1519\n",
            "  eval_pearson            =    -0.8016\n",
            "  eval_runtime            = 0:00:10.16\n",
            "  eval_samples            =       1500\n",
            "  eval_samples_per_second =    147.559\n",
            "  eval_spearmanr          =    -0.7958\n",
            "  eval_steps_per_second   =       0.59\n",
            "  size_of                 =  388381956\n",
            "[INFO|modelcard.py:444] 2022-10-25 14:49:23,649 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'dataset': {'name': 'GLUE STSB', 'type': 'glue', 'args': 'stsb'}}\n"
          ]
        }
      ],
      "source": [
        "!python ./run_glue_prun_final.py \\\n",
        "  --model_name_or_path pruned_bert \\\n",
        "  --task_name stsb \\\n",
        "  --do_eval \\\n",
        "  --max_seq_length 128 \\\n",
        "  --per_device_train_batch_size 64 \\\n",
        "  --per_device_eval_batch_size 256 \\\n",
        "  --learning_rate 5e-5 \\\n",
        "  --num_train_epochs 3 \\\n",
        "  --seed 1337 \\\n",
        "  --run_name \"test_32_off\" \\\n",
        "  --output_dir \"glue_bert_prune\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hP21_wBque0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0479cf23c69b4352809075b4abfcea78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f4a11b3ccbc4c27864bd291f96b969b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99492ae69c6f4573a1687eb65de2b831",
            "placeholder": "​",
            "style": "IPY_MODEL_58143b4ab43e45799f7f4cad22f9bac0",
            "value": "Downloading: 100%"
          }
        },
        "1d1071b04ea542ce9519e60155c7374e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23c9dae4777e4c9cad7b1e7fea1d26ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27c53645272f4b78a2070295a425eb80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a8028dfb7574bdfafa0443662f9fc71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b032a747ec64fc791ac92a7857ea3aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d640477df5d4a8eaaf80c375267b319": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58addd49a44c4634b305bc1dd0b7a0ad",
            "placeholder": "​",
            "style": "IPY_MODEL_3dfba4970497490f8e88f4ee159f8ad0",
            "value": "Downloading: 100%"
          }
        },
        "375c061414e440abb1a45bdf141ab4c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dfba4970497490f8e88f4ee159f8ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e556d3f46ca4218915b25b120cd88b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc08839a4b4b487ea108dc5d5ec6b773",
            "placeholder": "​",
            "style": "IPY_MODEL_8d0893e9119c48efa0ffd1daf6334ea0",
            "value": " 548M/548M [00:10&lt;00:00, 55.3MB/s]"
          }
        },
        "466ceee14a174560a35a2392ca657390": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c72c1157f9b48eab2231adff0ee7369": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "549f2533f4c84231bd5bf810eba107ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58143b4ab43e45799f7f4cad22f9bac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58addd49a44c4634b305bc1dd0b7a0ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a470ddf7c6b4249acd05b911df12b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c99f77127a44dfda80caa3fabc6d387": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60c951c812f04e48a36b16dfc4b00f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_466ceee14a174560a35a2392ca657390",
            "placeholder": "​",
            "style": "IPY_MODEL_f80c98660d6943388d7cd807339ed53f",
            "value": " 665/665 [00:00&lt;00:00, 8.90kB/s]"
          }
        },
        "71293a70e11b4a88ae339d1458b73551": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d25cb7ce051a4b60a918aba9382dcef9",
            "placeholder": "​",
            "style": "IPY_MODEL_5a470ddf7c6b4249acd05b911df12b19",
            "value": "Downloading: 100%"
          }
        },
        "72053f3d17ba4bfa841386c5d27851fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f681a802a84d5da0dbe4f57806c8af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76710fa79fad46ef96ae0a5b315efb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbe7fe8555a6401e84dd3638f147a36f",
            "placeholder": "​",
            "style": "IPY_MODEL_b64624db94f74a4b8a3aeb43b5307d61",
            "value": " 456k/456k [00:01&lt;00:00, 466kB/s]"
          }
        },
        "7a7de3163e7e473b9c52e4b3f3691489": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80505f8c0d594a7b8fe3759ccef985f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71293a70e11b4a88ae339d1458b73551",
              "IPY_MODEL_8c696eef99b841748e4469f9e178ebcb",
              "IPY_MODEL_805fe601916c40829e5d4adc2174d340"
            ],
            "layout": "IPY_MODEL_f79433e9a59b4cb4bedf12bb7a70dcf2"
          }
        },
        "805fe601916c40829e5d4adc2174d340": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b032a747ec64fc791ac92a7857ea3aa",
            "placeholder": "​",
            "style": "IPY_MODEL_5c99f77127a44dfda80caa3fabc6d387",
            "value": " 1.36M/1.36M [00:01&lt;00:00, 1.48MB/s]"
          }
        },
        "82f3cae63ea140d4b062393ee479604b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f4a11b3ccbc4c27864bd291f96b969b",
              "IPY_MODEL_9c7d0d8c096c45e4ad785665098f293c",
              "IPY_MODEL_3e556d3f46ca4218915b25b120cd88b7"
            ],
            "layout": "IPY_MODEL_d0c515cdcd2c44aa9abf1668f4c1eda2"
          }
        },
        "834d49dc228449bdb2436470aae0e463": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db3c732359c542c0b1456c12744112a7",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6827ff8dec04552a0a4bc3b5d0da12c",
            "value": 1042301
          }
        },
        "84a995961d2c48c2b977cf06380b454c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf8170e887b648ffb5f2c1ac537d9373",
              "IPY_MODEL_834d49dc228449bdb2436470aae0e463",
              "IPY_MODEL_8e9e69de49274b48bf02957247c4ee7c"
            ],
            "layout": "IPY_MODEL_d47e591313264d6ca99d9e98831407df"
          }
        },
        "881adf9ac86b419fa371fd0453e9734c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c696eef99b841748e4469f9e178ebcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_375c061414e440abb1a45bdf141ab4c0",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b74de86a0d5a49eda6d332e65ef6cd2b",
            "value": 1355256
          }
        },
        "8d0893e9119c48efa0ffd1daf6334ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8da931de989b436a9b08b27363c3b330": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e9e69de49274b48bf02957247c4ee7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0479cf23c69b4352809075b4abfcea78",
            "placeholder": "​",
            "style": "IPY_MODEL_1d1071b04ea542ce9519e60155c7374e",
            "value": " 1.04M/1.04M [00:01&lt;00:00, 1.02MB/s]"
          }
        },
        "99492ae69c6f4573a1687eb65de2b831": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c7d0d8c096c45e4ad785665098f293c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a8028dfb7574bdfafa0443662f9fc71",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27c53645272f4b78a2070295a425eb80",
            "value": 548118077
          }
        },
        "9d9a1da0bb3c4727bb2a502d0ff4dad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcdd09b510b34deb9f40a32554314caf",
              "IPY_MODEL_ad15986515b64fc7826eea15fd84e146",
              "IPY_MODEL_60c951c812f04e48a36b16dfc4b00f3b"
            ],
            "layout": "IPY_MODEL_72053f3d17ba4bfa841386c5d27851fe"
          }
        },
        "a122bb8bf70845659d95d85931f98170": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c72c1157f9b48eab2231adff0ee7369",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a7de3163e7e473b9c52e4b3f3691489",
            "value": 456318
          }
        },
        "ad15986515b64fc7826eea15fd84e146": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_881adf9ac86b419fa371fd0453e9734c",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa5aaa1672e2497b8a0bc227c88477fc",
            "value": 665
          }
        },
        "b64624db94f74a4b8a3aeb43b5307d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b74de86a0d5a49eda6d332e65ef6cd2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcdd09b510b34deb9f40a32554314caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6c2762d80d946b48fdc441c3babef0d",
            "placeholder": "​",
            "style": "IPY_MODEL_549f2533f4c84231bd5bf810eba107ce",
            "value": "Downloading: 100%"
          }
        },
        "c091e4e3e87341f985c9142046a4a390": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d640477df5d4a8eaaf80c375267b319",
              "IPY_MODEL_a122bb8bf70845659d95d85931f98170",
              "IPY_MODEL_76710fa79fad46ef96ae0a5b315efb09"
            ],
            "layout": "IPY_MODEL_75f681a802a84d5da0dbe4f57806c8af"
          }
        },
        "cf8170e887b648ffb5f2c1ac537d9373": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23c9dae4777e4c9cad7b1e7fea1d26ed",
            "placeholder": "​",
            "style": "IPY_MODEL_8da931de989b436a9b08b27363c3b330",
            "value": "Downloading: 100%"
          }
        },
        "d0c515cdcd2c44aa9abf1668f4c1eda2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d25cb7ce051a4b60a918aba9382dcef9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d47e591313264d6ca99d9e98831407df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db3c732359c542c0b1456c12744112a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c2762d80d946b48fdc441c3babef0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6827ff8dec04552a0a4bc3b5d0da12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f79433e9a59b4cb4bedf12bb7a70dcf2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f80c98660d6943388d7cd807339ed53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa5aaa1672e2497b8a0bc227c88477fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbe7fe8555a6401e84dd3638f147a36f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc08839a4b4b487ea108dc5d5ec6b773": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
